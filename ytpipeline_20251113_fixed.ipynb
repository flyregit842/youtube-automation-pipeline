{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b654f9a",
   "metadata": {
    "tags": [
     "step0"
    ]
   },
   "source": [
    "## STEP 0 – Environment & Project Bootstrap\n",
    "Creates project folder, baseline files, installs minimal Python packages, checks ffmpeg/ffprobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e06a39",
   "metadata": {
    "tags": [
     "step0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Bootstrapping project: C:\\Users\\flyre\\mynotebooks\n",
      "[OK] .env exists\n",
      "[OK] text.txt exists\n",
      "[OK] bgm.mp3 exists\n",
      "[OK] plan_initial.yaml exists\n",
      "[pip] Installing python-dotenv ...\n",
      "[OK] plan_current.yaml synced (10 scenes).\n",
      "\n",
      "--- STEP 0 SUMMARY ---\n",
      "{\n",
      "  \"project_dir\": \"C:\\\\Users\\\\flyre\\\\mynotebooks\",\n",
      "  \"assets_dir\": \"C:\\\\Users\\\\flyre\\\\mynotebooks\\\\assets\",\n",
      "  \"fonts_dir\": \"C:\\\\Users\\\\flyre\\\\mynotebooks\\\\fonts\",\n",
      "  \"env_file\": \"C:\\\\Users\\\\flyre\\\\mynotebooks\\\\.env\",\n",
      "  \"text_file\": \"C:\\\\Users\\\\flyre\\\\mynotebooks\\\\text.txt\",\n",
      "  \"plan_initial_yaml\": \"C:\\\\Users\\\\flyre\\\\mynotebooks\\\\plan_initial.yaml\",\n",
      "  \"plan_current_yaml\": \"C:\\\\Users\\\\flyre\\\\mynotebooks\\\\plan_current.yaml\",\n",
      "  \"scenes_in_plan_current\": 10,\n",
      "  \"packages\": {\n",
      "    \"pyyaml\": \"present\",\n",
      "    \"pillow\": \"present\",\n",
      "    \"ipywidgets\": \"present\",\n",
      "    \"python-dotenv\": \"missing\"\n",
      "  },\n",
      "  \"env_loaded\": true,\n",
      "  \"api_keys_status\": {\n",
      "    \"OPENAI_API_KEY\": \"OK\",\n",
      "    \"AZURE_SPEECH_KEY\": \"OK\",\n",
      "    \"AZURE_SPEECH_REGION\": \"SHORT\",\n",
      "    \"MINIMAX_SPEECH_KEY\": \"OK\",\n",
      "    \"MINIMAX_GROUP_ID\": \"OK\",\n",
      "    \"ELEVENLABS_API_KEY\": \"MISSING\"\n",
      "  },\n",
      "  \"ffmpeg\": \"C:\\\\Users\\\\flyre\\\\Downloads\\\\ffmpeg-8.0-full_build\\\\ffmpeg-8.0-full_build\\\\bin\\\\ffmpeg.EXE\",\n",
      "  \"ffprobe\": \"C:\\\\Users\\\\flyre\\\\Downloads\\\\ffmpeg-8.0-full_build\\\\ffmpeg-8.0-full_build\\\\bin\\\\ffprobe.EXE\",\n",
      "  \"audio_files_found\": 46,\n",
      "  \"image_files_found\": 107,\n",
      "  \"pillow_thumbnail_test\": {\n",
      "    \"file\": \"C:\\\\Users\\\\flyre\\\\mynotebooks\\\\pillow_test.png\",\n",
      "    \"size\": [\n",
      "      60,\n",
      "      30\n",
      "    ]\n",
      "  },\n",
      "  \"next_steps\": [\n",
      "    \"Edit text.txt lines for your scenes (each line = one scene).\",\n",
      "    \"Run Step 1 editor (auto-assign UI with thumbnails).\",\n",
      "    \"Use Quick Check -> Save YAML.\",\n",
      "    \"Run Step 2 renderer.\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "✅ ffmpeg ready.\n",
      "⚠️  Missing API keys in .env: ELEVENLABS_API_KEY (edit .env)\n",
      "Step 0 complete.\n"
     ]
    }
   ],
   "source": [
    "# Step 0 — Final Bootstrap (explicit installs + env + plan sync + optional Pillow test)\n",
    "# Safe to rerun. Does NOT overwrite existing API values in .env.\n",
    "#\n",
    "# Features:\n",
    "#   - Installs pyyaml, pillow, ipywidgets, python-dotenv (unless SKIP_INSTALL=True)\n",
    "#   - Loads .env\n",
    "#   - Creates project folder layout\n",
    "#   - Seeds text.txt if missing\n",
    "#   - Maintains plan_initial.yaml (only created if missing)\n",
    "#   - Synchronizes plan_current.yaml scenes to text.txt\n",
    "#   - Verifies ffmpeg / ffprobe availability\n",
    "#   - Prints API key status and asset counts\n",
    "#   - Optional Pillow sanity test (THUMB_TEST=True)\n",
    "#\n",
    "# Change PROJECT_DIR if needed; or set env MY_VIDEO_PROJECT_DIR before running.\n",
    "# After this: run Step 1 editor (auto-assign + preview).\n",
    "\n",
    "import os, sys, json, shutil, datetime, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- User Config ----------------\n",
    "main_dir = r\"C:/Users/flyre/mynotebooks\"\n",
    "PROJECT_DIR = Path(os.environ.get(\"MY_VIDEO_PROJECT_DIR\", r\"C:\\Users\\flyre\\mynotebooks\")).expanduser()\n",
    "SKIP_INSTALL = False          # Set True to skip pip installs (if environment already prepared)\n",
    "THUMB_TEST   = True           # Create & load a small test image via Pillow to confirm it's working\n",
    "REQUIRED_PACKAGES = [\"pyyaml\", \"pillow\", \"ipywidgets\", \"python-dotenv\"]\n",
    "\n",
    "# ---------------- Paths ----------------\n",
    "ASSETS_DIR  = PROJECT_DIR / \"assets\"\n",
    "FONTS_DIR   = PROJECT_DIR / \"fonts\"\n",
    "ENV_FILE    = PROJECT_DIR / \".env\"\n",
    "TEXT_FILE   = PROJECT_DIR / \"text.txt\"\n",
    "PLAN_INIT_Y = PROJECT_DIR / \"plan_initial.yaml\"\n",
    "PLAN_INIT_J = PROJECT_DIR / \"plan_initial.json\"\n",
    "PLAN_CUR_Y  = PROJECT_DIR / \"plan_current.yaml\"\n",
    "PLAN_CUR_J  = PROJECT_DIR / \"plan_current.json\"\n",
    "BGM_FILE    = PROJECT_DIR / \"bgm.mp3\"\n",
    "\n",
    "# ---------------- Templates ----------------\n",
    "ENV_TEMPLATE = (\n",
    "    \"OPENAI_API_KEY=\\n\"\n",
    "    \"AZURE_SPEECH_KEY=\\n\"\n",
    "    \"AZURE_SPEECH_REGION=\\n\"\n",
    "    \"MINIMAX_SPEECH_KEY=\\n\"\n",
    "    \"MINIMAX_GROUP_ID=\\n\"\n",
    "    \"ELEVENLABS_API_KEY=\\n\"\n",
    ")\n",
    "\n",
    "TEXT_TEMPLATE = \"請在此輸入影片腳本文字，每行為一個分鏡。\\n\"\n",
    "\n",
    "PLAN_SKELETON = {\n",
    "    \"project_title\": \"DemoVideo\",\n",
    "    \"date\": datetime.datetime.now().strftime('%Y%m%d'),\n",
    "    \"version\": 1,\n",
    "    \"global\": {\n",
    "        \"resolution\": [1920,1080],\n",
    "        \"fps\": 30,\n",
    "        \"loudnorm\": {\"target_i\": -14, \"target_tp\": -1.5, \"target_lra\": 11, \"mode\": \"two-pass\"},\n",
    "        \"music\": {\n",
    "            \"file\": \"bgm.mp3\",\n",
    "            \"gain_db\": -12,\n",
    "            \"ducking\": {\"enabled\": True, \"threshold\": 0.05, \"ratio\": 8, \"attack_ms\": 10, \"release_ms\": 300}\n",
    "        },\n",
    "        \"subtitle\": {\n",
    "            \"font_family\": \"Noto Sans CJK TC\",\n",
    "            \"font_size\": 48,\n",
    "            \"outline\": 3,\n",
    "            \"shadow\": 0,\n",
    "            \"color\": \"#FFFFFF\",\n",
    "            \"align\": \"bottom-center\",\n",
    "            \"margin_v\": 60\n",
    "        },\n",
    "        \"transitions\": {\"default_type\": \"crossfade\", \"default_duration\": 0.6}\n",
    "    },\n",
    "    \"scenes\": []\n",
    "}\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ensure_file(p: Path, content: str):\n",
    "    if not p.exists():\n",
    "        p.write_text(content, encoding=\"utf-8\")\n",
    "        print(f\"[INIT] Created {p.name}\")\n",
    "    else:\n",
    "        print(f\"[OK] {p.name} exists\")\n",
    "\n",
    "def pip_install(pkg: str):\n",
    "    print(f\"[pip] Installing {pkg} ...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "def ensure_packages(package_list):\n",
    "    installed_status = {}\n",
    "    for pkg in package_list:\n",
    "        mod_name = \"yaml\" if pkg == \"pyyaml\" else (\"PIL\" if pkg == \"pillow\" else pkg)\n",
    "        try:\n",
    "            __import__(mod_name)\n",
    "            installed_status[pkg] = \"present\"\n",
    "        except ImportError:\n",
    "            installed_status[pkg] = \"missing\"\n",
    "    to_install = [p for p, st in installed_status.items() if st == \"missing\"]\n",
    "    if to_install and not SKIP_INSTALL:\n",
    "        for p in to_install:\n",
    "            pip_install(p)\n",
    "    elif to_install and SKIP_INSTALL:\n",
    "        print(\"[SKIP_INSTALL] Missing packages not installed:\", to_install)\n",
    "    # Re-import\n",
    "    import importlib\n",
    "    globals()[\"yaml\"] = importlib.import_module(\"yaml\")\n",
    "    try:\n",
    "        globals()[\"PIL_Image\"] = importlib.import_module(\"PIL.Image\")\n",
    "    except Exception:\n",
    "        globals()[\"PIL_Image\"] = None\n",
    "    try:\n",
    "        globals()[\"dotenv\"] = importlib.import_module(\"dotenv\")\n",
    "    except Exception:\n",
    "        globals()[\"dotenv\"] = None\n",
    "    return installed_status\n",
    "\n",
    "def load_text_lines():\n",
    "    if not TEXT_FILE.exists():\n",
    "        return []\n",
    "    return [l.strip() for l in TEXT_FILE.read_text(encoding=\"utf-8\").splitlines() if l.strip()]\n",
    "\n",
    "def create_initial_plan():\n",
    "    import yaml\n",
    "    PLAN_INIT_Y.write_text(yaml.safe_dump(PLAN_SKELETON, allow_unicode=True), encoding=\"utf-8\")\n",
    "    PLAN_INIT_J.write_text(json.dumps(PLAN_SKELETON, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(\"[INIT] plan_initial.yaml/json created\")\n",
    "\n",
    "def sync_plan_current():\n",
    "    import yaml\n",
    "    if PLAN_CUR_Y.exists():\n",
    "        try:\n",
    "            plan = yaml.safe_load(PLAN_CUR_Y.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            plan = None\n",
    "    else:\n",
    "        plan = None\n",
    "    lines = load_text_lines()\n",
    "    if plan is None:\n",
    "        if PLAN_INIT_Y.exists():\n",
    "            try:\n",
    "                plan = yaml.safe_load(PLAN_INIT_Y.read_text(encoding=\"utf-8\"))\n",
    "            except Exception:\n",
    "                plan = PLAN_SKELETON.copy()\n",
    "        else:\n",
    "            plan = PLAN_SKELETON.copy()\n",
    "\n",
    "    existing_map = {sc.get(\"number\"): sc for sc in plan.get(\"scenes\", []) if isinstance(sc, dict)}\n",
    "    new_scenes = []\n",
    "    for idx, line in enumerate(lines, start=1):\n",
    "        prev = existing_map.get(idx, {})\n",
    "        new_scenes.append({\n",
    "            \"number\": idx,\n",
    "            \"raw_text\": line,\n",
    "            \"subtitle_text\": prev.get(\"subtitle_text\", line),\n",
    "            \"ai_prompt\": prev.get(\"ai_prompt\", line),\n",
    "            \"tags\": prev.get(\"tags\", []),\n",
    "            \"notes\": prev.get(\"notes\", \"\"),\n",
    "            \"tts\": prev.get(\"tts\", {\"server\":\"local\",\"voice\":\"default\",\"speed\":1.0}),\n",
    "            \"transition\": prev.get(\"transition\", {\n",
    "                \"type\": plan.get(\"global\", {}).get(\"transitions\", {}).get(\"default_type\", \"none\"),\n",
    "                \"duration\": plan.get(\"global\", {}).get(\"transitions\", {}).get(\"default_duration\", 0.0)\n",
    "            }),\n",
    "            \"flags\": prev.get(\"flags\", {\"split_subtitle_by_punctuation\": True}),\n",
    "            \"hashes\": prev.get(\"hashes\", {}),\n",
    "            \"duration_override\": prev.get(\"duration_override\"),\n",
    "            \"audio_file\": prev.get(\"audio_file\"),\n",
    "            \"image_file\": prev.get(\"image_file\"),\n",
    "        })\n",
    "    plan[\"scenes\"] = new_scenes\n",
    "    if \"global\" not in plan:\n",
    "        plan[\"global\"] = PLAN_SKELETON[\"global\"]\n",
    "    plan[\"date\"] = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    PLAN_CUR_Y.write_text(yaml.safe_dump(plan, allow_unicode=True), encoding=\"utf-8\")\n",
    "    PLAN_CUR_J.write_text(json.dumps(plan, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"[OK] plan_current.yaml synced ({len(new_scenes)} scenes).\")\n",
    "    return plan\n",
    "\n",
    "def load_env():\n",
    "    if ENV_FILE.exists() and globals().get(\"dotenv\"):\n",
    "        globals()[\"dotenv\"].load_dotenv(dotenv_path=ENV_FILE)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def tool_path(name):\n",
    "    return shutil.which(name) or \"NOT_FOUND\"\n",
    "\n",
    "def key_status(k):\n",
    "    v = os.environ.get(k, \"\")\n",
    "    if not v:\n",
    "        return \"MISSING\"\n",
    "    if len(v.strip()) < 10:\n",
    "        return \"SHORT\"\n",
    "    return \"OK\"\n",
    "\n",
    "def list_assets():\n",
    "    audio = sorted([p.name for p in PROJECT_DIR.glob(\"*.mp3\")] +\n",
    "                   [p.name for p in PROJECT_DIR.glob(\"*.wav\")] +\n",
    "                   [p.name for p in PROJECT_DIR.glob(\"*.m4a\")])\n",
    "    images = []\n",
    "    for pat in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.webp\"):\n",
    "        images += [p.name for p in PROJECT_DIR.glob(pat)]\n",
    "    return audio, sorted(images)\n",
    "\n",
    "def pillow_test():\n",
    "    if not PIL_Image or not THUMB_TEST:\n",
    "        return None\n",
    "    try:\n",
    "        test_png = PROJECT_DIR / \"pillow_test.png\"\n",
    "        if not test_png.exists():\n",
    "            img = PIL_Image.new(\"RGB\", (200, 100), color=(30, 120, 200))\n",
    "            img.save(str(test_png), \"PNG\")\n",
    "        # load & verify thumbnail ability\n",
    "        img2 = PIL_Image.open(str(test_png))\n",
    "        img2.thumbnail((60, 40))\n",
    "        return {\"file\": str(test_png), \"size\": img2.size}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# ---------------- Execute ----------------\n",
    "print(f\"[INFO] Bootstrapping project: {PROJECT_DIR}\")\n",
    "ensure_dir(PROJECT_DIR)\n",
    "ensure_dir(ASSETS_DIR)\n",
    "ensure_dir(FONTS_DIR)\n",
    "\n",
    "ensure_file(ENV_FILE, ENV_TEMPLATE)\n",
    "ensure_file(TEXT_FILE, TEXT_TEMPLATE)\n",
    "ensure_file(BGM_FILE, \"\")\n",
    "\n",
    "if not PLAN_INIT_Y.exists():\n",
    "    create_initial_plan()\n",
    "else:\n",
    "    print(\"[OK] plan_initial.yaml exists\")\n",
    "\n",
    "pkg_status = ensure_packages(REQUIRED_PACKAGES)\n",
    "env_loaded = load_env()\n",
    "plan_current = sync_plan_current()\n",
    "\n",
    "ffmpeg_path  = tool_path(\"ffmpeg\")\n",
    "ffprobe_path = tool_path(\"ffprobe\")\n",
    "\n",
    "api_keys = {\n",
    "    \"OPENAI_API_KEY\": key_status(\"OPENAI_API_KEY\"),\n",
    "    \"AZURE_SPEECH_KEY\": key_status(\"AZURE_SPEECH_KEY\"),\n",
    "    \"AZURE_SPEECH_REGION\": key_status(\"AZURE_SPEECH_REGION\"),\n",
    "    \"MINIMAX_SPEECH_KEY\": key_status(\"MINIMAX_SPEECH_KEY\"),\n",
    "    \"MINIMAX_GROUP_ID\": key_status(\"MINIMAX_GROUP_ID\"),\n",
    "    \"ELEVENLABS_API_KEY\": key_status(\"ELEVENLABS_API_KEY\"),\n",
    "}\n",
    "\n",
    "audio_files, image_files = list_assets()\n",
    "thumb_result = pillow_test()\n",
    "\n",
    "summary = {\n",
    "    \"project_dir\": str(PROJECT_DIR),\n",
    "    \"assets_dir\": str(ASSETS_DIR),\n",
    "    \"fonts_dir\": str(FONTS_DIR),\n",
    "    \"env_file\": str(ENV_FILE),\n",
    "    \"text_file\": str(TEXT_FILE),\n",
    "    \"plan_initial_yaml\": str(PLAN_INIT_Y),\n",
    "    \"plan_current_yaml\": str(PLAN_CUR_Y),\n",
    "    \"scenes_in_plan_current\": len(plan_current.get(\"scenes\", [])),\n",
    "    \"packages\": pkg_status,\n",
    "    \"env_loaded\": env_loaded,\n",
    "    \"api_keys_status\": api_keys,\n",
    "    \"ffmpeg\": ffmpeg_path,\n",
    "    \"ffprobe\": ffprobe_path,\n",
    "    \"audio_files_found\": len(audio_files),\n",
    "    \"image_files_found\": len(image_files),\n",
    "    \"pillow_thumbnail_test\": thumb_result,\n",
    "    \"next_steps\": [\n",
    "        \"Edit text.txt lines for your scenes (each line = one scene).\",\n",
    "        \"Run Step 1 editor (auto-assign UI with thumbnails).\",\n",
    "        \"Use Quick Check -> Save YAML.\",\n",
    "        \"Run Step 2 renderer.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n--- STEP 0 SUMMARY ---\")\n",
    "print(json.dumps(summary, ensure_ascii=False, indent=2))\n",
    "\n",
    "if ffmpeg_path == \"NOT_FOUND\" or ffprobe_path == \"NOT_FOUND\":\n",
    "    print(\"\\n⚠️  ffmpeg/ffprobe missing. Install before rendering (e.g. Windows: choco install ffmpeg).\")\n",
    "else:\n",
    "    print(\"\\n✅ ffmpeg ready.\")\n",
    "\n",
    "missing_keys = [k for k, st in api_keys.items() if st == \"MISSING\"]\n",
    "if missing_keys:\n",
    "    print(f\"⚠️  Missing API keys in .env: {', '.join(missing_keys)} (edit .env)\")\n",
    "\n",
    "print(\"Step 0 complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86717802-2750-4b49-9a4d-002ce9e941ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[初始化] 主目錄 = C:\\Users\\flyre\\mynotebooks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c784b79c9df745f9b8510653fd0b9cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>步驟0：全域設定（前製 TTS / 後製效果 / 字幕大小 / 一鍵檔位）</b>'), HTML(value='<u>一鍵檔位</u>（點選後面板會更新，記得…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a020e7be0f6c4f2a948b4f5de2aaa700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>步驟1：分鏡編輯</b> — 每個場景：上框字幕 + 右側音訊選擇/TTS（下一行播放器）；下框圖片提示 + 右側圖片選擇/AI生圖；最右側圖片預覽'), Te…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-31 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1597, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "UnicodeDecodeError: 'cp950' codec can't decode byte 0xaf in position 2309: illegal multibyte sequence\n",
      "Exception in thread Thread-45 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1597, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "UnicodeDecodeError: 'cp950' codec can't decode byte 0xaf in position 2309: illegal multibyte sequence\n",
      "Exception in thread Thread-59 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1597, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "UnicodeDecodeError: 'cp950' codec can't decode byte 0xaf in position 2309: illegal multibyte sequence\n",
      "Exception in thread Thread-73 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\flyre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1597, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "UnicodeDecodeError: 'cp950' codec can't decode byte 0xaf in position 2309: illegal multibyte sequence\n"
     ]
    }
   ],
   "source": [
    "# 一站式：步驟0（全域設定：TTS / 字幕比例 / 後製 + 內建飄落：簡易/進階 + 一鍵檔位 省資源/均衡/頂規）\n",
    "#        步驟1（分鏡編輯）→ 步驟2（輸出）\n",
    "# 檔位說明：\n",
    "# - 省資源：720p/25fps、關閉重濾鏡、內建(簡易)飄落、進階禁用、CPU 最省\n",
    "# - 均衡：1080p/25fps、內建(進階)半尺寸生成（疊時放大）、VP9 快速參數\n",
    "# - 頂規：1080p/25fps（可自行改 4K）、內建(進階)全尺寸、VP9 較高品質參數（慢，但最自然）\n",
    "#\n",
    "# 使用方式：\n",
    "# 1) 上一格設定：main_dir = r\"C:/Users/you/yourfolder\"\n",
    "# 2) 執行本格 → 步驟0：點「一鍵檔位」(省資源/均衡/頂規) → 看面板參數有變 → 按「儲存設定」\n",
    "# 3) 步驟1：載入文字(重建) → 逐場景補音訊/圖片（TTS/AI生圖）→ 可按「儲存規劃檔」\n",
    "# 4) 按「輸出影片」，會自動用檔位覆蓋解析度/幀率並套特效；透明特效首次會生成，再者重用\n",
    "\n",
    "import os, re, json, yaml, subprocess, shutil, datetime, hashlib, textwrap, base64, math, random, tempfile\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as W\n",
    "\n",
    "# ---------------- 基本環境 ----------------\n",
    "try:\n",
    "    main_dir\n",
    "except NameError:\n",
    "    main_dir = str(Path.cwd())\n",
    "main_dir = Path(main_dir)\n",
    "if not main_dir.exists():\n",
    "    raise RuntimeError(f\"主目錄不存在: {main_dir}\")\n",
    "print(f\"[初始化] 主目錄 = {main_dir}\")\n",
    "\n",
    "PLAN_CURRENT   = \"plan_current.yaml\"\n",
    "HANDSHAKE_NAME = \"plan_handshake.json\"\n",
    "LOCK_NAME      = \"plan_lock.json\"\n",
    "TEXT_FILE_NAME = \"text.txt\"\n",
    "SETTINGS_NAME  = \"settings.json\"\n",
    "\n",
    "DEFAULT_FALLBACK_DURATION = 3.0\n",
    "LOUDNORM_I   = -16.0\n",
    "LOUDNORM_TP  = -1.0\n",
    "LOUDNORM_LRA = 11.0\n",
    "FONTNAME_FORCE_STYLE = \"Arial\"\n",
    "\n",
    "# 環境變數（若使用雲端 TTS 需設定）\n",
    "OPENAI_API_KEY  = os.environ.get(\"OPENAI_API_KEY\",\"\").strip()\n",
    "OPENAI_ORG_ID   = os.environ.get(\"OPENAI_ORG_ID\",\"\").strip()\n",
    "AZURE_TTS_KEY   = os.environ.get(\"AZURE_TTS_KEY\",\"\").strip()\n",
    "AZURE_TTS_REGION= os.environ.get(\"AZURE_TTS_REGION\",\"\").strip()\n",
    "MINIMAX_API_KEY = os.environ.get(\"MINIMAX_API_KEY\",\"\").strip()\n",
    "\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def convert_webm_overlay_to_pngs(webm_path, png_prefix, frame_rate=25):\n",
    "    \"\"\"\n",
    "    將 webm 特效檔解出 png 幀圖，回傳 png 路徑 pattern字串與目錄\n",
    "    \"\"\"\n",
    "    webm_path = Path(webm_path)\n",
    "    png_dir = webm_path.parent / \"_overlaytemp\"\n",
    "    png_dir.mkdir(exist_ok=True)\n",
    "    png_pattern = str(png_dir / f\"{png_prefix}_%06d.png\")\n",
    "    for f in png_dir.glob(f\"{png_prefix}_*.png\"):\n",
    "        f.unlink()\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", str(webm_path),\n",
    "        \"-vf\", \"pad=ceil(iw/2)*2:ceil(ih/2)*2\",\n",
    "        png_pattern\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "    return png_pattern, png_dir\n",
    "\n",
    "def cleanup_overlay_pngs(png_dir, png_prefix):\n",
    "    for f in png_dir.glob(f\"{png_prefix}_*.png\"):\n",
    "        f.unlink()\n",
    "    try:\n",
    "        png_dir.rmdir()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def postprocess_final_video(base_plain: Path, settings: dict, out_path: Path, base_w=1920, base_h=1080, base_fps=25):\n",
    "    post = (settings.get(\"post\") or {})\n",
    "    nothing = True\n",
    "    if (post.get(\"color\") or {}).get(\"enabled\", False): nothing=False\n",
    "    if (post.get(\"denoise\") or {}).get(\"enabled\", False): nothing=False\n",
    "    if (post.get(\"sharpen\") or {}).get(\"enabled\", False): nothing=False\n",
    "    if (post.get(\"fps_interp\") or {}).get(\"enabled\", False): nothing=False\n",
    "    for ov in (post.get(\"overlays\") or []):\n",
    "        if ov.get(\"enabled\", False): nothing=False\n",
    "    if nothing:\n",
    "        shutil.copyfile(base_plain, out_path); return True, \"copy\"\n",
    "\n",
    "    extra_inputs, fc, vout = build_filter_chain_and_inputs(base_w, base_h, settings, base_fps=base_fps)\n",
    "\n",
    "    # --- 新增判斷：若唯一 overlay 為 .webm，則轉成 png 疊圖 ---\n",
    "    # 只補單一 webm overlay（如有多層可再遞迴；現在補你特效全黑問題）    # --- 新：跨option安全尋找 webm overlay 檔案 ---\n",
    "    webm_overlay = None\n",
    "    # extra_inputs 常是：['-stream_loop', '-1', '-i', 'xxx.webm', ...]\n",
    "    for i in range(len(extra_inputs) - 1):\n",
    "        if (\n",
    "            isinstance(extra_inputs[i], str)\n",
    "            and extra_inputs[i] == \"-i\"\n",
    "            and isinstance(extra_inputs[i + 1], str)\n",
    "            and extra_inputs[i + 1].lower().endswith(\".webm\")\n",
    "        ):\n",
    "            webm_overlay = Path(extra_inputs[i + 1])\n",
    "            break\n",
    "    # 備援：暴力掃 .webm（萬一 pattern 變動也不會失效）\n",
    "    if not webm_overlay:\n",
    "        for item in extra_inputs:\n",
    "            if isinstance(item, str) and item.lower().endswith(\".webm\"):\n",
    "                webm_overlay = Path(item)\n",
    "                break\n",
    "\n",
    "    if webm_overlay and \"overlay\" in fc:\n",
    "        # (1) 先拆 webm 成 png\n",
    "        png_pattern, png_dir = convert_webm_overlay_to_pngs(webm_overlay, \"adv_overlay\", frame_rate=base_fps)\n",
    "        # (2) 用 png 幀序列疊圖\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\", \"-i\", str(base_plain),\n",
    "            \"-framerate\", str(base_fps), \"-i\", png_pattern,\n",
    "            \"-filter_complex\", \"[0:v][1:v]overlay=0:0:shortest=1[v1]\",\n",
    "            \"-map\", \"[v1]\", \"-map\", \"0:a?\", \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\", \"-c:a\", \"aac\", \"-movflags\", \"+faststart\", str(out_path)\n",
    "        ]\n",
    "        res = subprocess.run(cmd, capture_output=True)\n",
    "        err = res.stderr.decode(\"utf-8\", errors=\"ignore\") if res.stderr else \"\"        \n",
    "        cleanup_overlay_pngs(png_dir, \"adv_overlay\")\n",
    "        ok = (res.returncode==0 and out_path.exists() and out_path.stat().st_size>0)\n",
    "        return ok, (res.stderr or \"\")[-400:] if not ok else \"ok\"\n",
    "    else:\n",
    "        # 沒有 webm overlay, 走原本路徑\n",
    "        cmd = [\"ffmpeg\",\"-y\",\"-i\",str(base_plain)] + extra_inputs + [\n",
    "            \"-filter_complex\", fc, \"-map\", f\"[{vout}]\", \"-map\", \"0:a?\",\"-c:v\",\"libx264\",\"-pix_fmt\",\"yuv420p\",\"-c:a\",\"aac\",\"-movflags\",\"+faststart\", str(out_path)\n",
    "        ]\n",
    "        res=_run(cmd, capture=True)\n",
    "        ok = (res.returncode==0 and out_path.exists() and out_path.stat().st_size>0)\n",
    "        return ok, (res.stderr or \"\")[-400:] if not ok else \"ok\"\n",
    "\n",
    "# ---------------- 常用工具 ----------------\n",
    "def _run(cmd, capture=False):\n",
    "    cmd = [str(c) for c in cmd]\n",
    "    return subprocess.run(cmd,\n",
    "                          stdout=(subprocess.PIPE if capture else None),\n",
    "                          stderr=(subprocess.PIPE if capture else None),\n",
    "                          text=True)\n",
    "\n",
    "def _md5_text(txt: str):\n",
    "    return hashlib.md5(txt.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def _ffprobe_duration(path: Path):\n",
    "    if not shutil.which(\"ffprobe\"):\n",
    "        return None\n",
    "    r = subprocess.run([\"ffprobe\",\"-v\",\"error\",\"-show_entries\",\"format=duration\",\n",
    "                        \"-of\",\"default=noprint_wrappers=1:nokey=1\", str(path)],\n",
    "                       stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    try:\n",
    "        return max(0.1, float((r.stdout or \"\").strip()))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def atomic_write_text(path: Path, text: str):\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    tmp.write_text(text, encoding=\"utf-8\")\n",
    "    tmp.replace(path)\n",
    "\n",
    "def gather_images():\n",
    "    exts = {\".png\",\".jpg\",\".jpeg\",\".webp\"}\n",
    "    return [\"\"] + [p.name for p in sorted(main_dir.iterdir()) if p.suffix.lower() in exts]\n",
    "\n",
    "def gather_audios():\n",
    "    exts = {\".mp3\",\".wav\",\".m4a\",\".aac\",\".flac\",\".ogg\"}\n",
    "    return [\"\"] + [p.name for p in sorted(main_dir.iterdir()) if p.suffix.lower() in exts]\n",
    "\n",
    "def gather_overlay_candidates():\n",
    "    exts = {\".mp4\",\".mov\",\".webm\",\".mkv\",\".avi\"}\n",
    "    return [\"\"] + [p.name for p in sorted(main_dir.iterdir()) if p.suffix.lower() in exts]\n",
    "\n",
    "def ensure_text_lines():\n",
    "    txt = main_dir / TEXT_FILE_NAME\n",
    "    if not txt.exists():\n",
    "        return []\n",
    "    return [l.strip() for l in txt.read_text(encoding=\"utf-8\").splitlines() if l.strip()]\n",
    "\n",
    "# ---------------- 設定（讀寫 + 預設 + 檔位） ----------------\n",
    "def default_settings():\n",
    "    return {\n",
    "        \"tts\": {\n",
    "            \"provider\": \"OPENAI\",\n",
    "            \"openai\": {\"model\":\"tts-1\",\"voice\":\"alloy\",\"format\":\"mp3\"},\n",
    "            \"azure\":  {\"region\":\"\", \"voice\":\"zh-TW-HsiaoChenNeural\", \"rate_pct\":0, \"pitch_pct\":0, \"format\":\"audio-24khz-48kbitrate-mono-mp3\"},\n",
    "            \"minimax\":{\"model\":\"speech-01\",\"voice_id\":\"female-1\",\"format\":\"mp3\"}\n",
    "        },\n",
    "        \"subs\": {\"scale_pct\": 125},\n",
    "        \"profile\": {\n",
    "            \"name\": \"eco\",                 # eco | balanced | ultra\n",
    "            \"output\": {\"w\":1280,\"h\":720,\"fps\":25},\n",
    "            \"adv_half_res\": True,          # 進階粒子素材半尺寸生成(疊時放大)\n",
    "            \"vp9\": {\"crf\":32, \"cpu_used\":8, \"tile_columns\":2, \"row_mt\":1, \"auto_alt_ref\":0}\n",
    "        },\n",
    "        \"post\": {\n",
    "            \"denoise\": {\"enabled\": False, \"preset\":\"medium\"},\n",
    "            \"sharpen\": {\"enabled\": False, \"amount\": 0.8},\n",
    "            \"color\":   {\"enabled\": False, \"brightness\":0.0, \"contrast\":1.0, \"saturation\":1.0},\n",
    "            \"fps_interp\": {\"enabled\": False, \"fps\": 60},\n",
    "            \"overlays\": [\n",
    "                {\n",
    "                    \"enabled\": True,\n",
    "                    \"mode\": \"builtin_simple\",   # file | builtin_simple | builtin_advanced\n",
    "                    \"file\": \"\",\n",
    "                    \"type\": \"alpha\",\n",
    "                    \"opacity\": 1.0,\n",
    "                    \"scale_to_output\": True,\n",
    "                    \"black\": {\"mode\":\"screen\"},\n",
    "                    \"greenscreen\":{\"color\":\"0x00FF00\",\"similarity\":0.20,\"blend\":0.10},\n",
    "                    \"simple\":   {\"kind\":\"snow\",\"density\":35,\"size\":36,\"speed\":130,\"color\":\"white\"},\n",
    "                    \"advanced\": {\"kind\":\"snow\",\"density\":60,\"size_min\":24,\"size_max\":64,\"speed_min\":60,\"speed_max\":180,\n",
    "                                 \"drift\":60,\"turbulence\":25,\"rotation_min\":-60,\"rotation_max\":60,\n",
    "                                 \"layers\":{\"near\":0.4,\"mid\":0.35,\"far\":0.25},\"loop_sec\":8,\"seed\":1337,\"texture_file\":\"\"}\n",
    "                },\n",
    "                {\n",
    "                    \"enabled\": False,\n",
    "                    \"mode\": \"builtin_simple\",\n",
    "                    \"file\": \"\",\n",
    "                    \"type\": \"alpha\",\n",
    "                    \"opacity\": 0.9,\n",
    "                    \"scale_to_output\": True,\n",
    "                    \"black\": {\"mode\":\"screen\"},\n",
    "                    \"greenscreen\":{\"color\":\"0x00FF00\",\"similarity\":0.20,\"blend\":0.10},\n",
    "                    \"simple\":   {\"kind\":\"leaves\",\"density\":20,\"size\":48,\"speed\":160,\"color\":\"white\"},\n",
    "                    \"advanced\": {\"kind\":\"leaves\",\"density\":36,\"size_min\":24,\"size_max\":72,\"speed_min\":80,\"speed_max\":160,\n",
    "                                 \"drift\":90,\"turbulence\":35,\"rotation_min\":-120,\"rotation_max\":120,\n",
    "                                 \"layers\":{\"near\":0.5,\"mid\":0.3,\"far\":0.2},\"loop_sec\":8,\"seed\":2025,\"texture_file\":\"\"}\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "def settings_path():\n",
    "    return main_dir/SETTINGS_NAME\n",
    "\n",
    "def load_settings():\n",
    "    sp = settings_path()\n",
    "    if sp.exists():\n",
    "        try:\n",
    "            s = json.loads(sp.read_text(encoding=\"utf-8\"))\n",
    "            # 合併新欄位預設\n",
    "            def merge_defaults(d, tmpl):\n",
    "                for k,v in tmpl.items():\n",
    "                    if k not in d:\n",
    "                        d[k]=v\n",
    "                    else:\n",
    "                        if isinstance(v, dict) and isinstance(d[k], dict):\n",
    "                            merge_defaults(d[k], v)\n",
    "                return d\n",
    "            s = merge_defaults(s, default_settings())\n",
    "            return s\n",
    "        except:\n",
    "            pass\n",
    "    s = default_settings()\n",
    "    save_settings(s)\n",
    "    return s\n",
    "\n",
    "def save_settings(s):\n",
    "    settings_path().write_text(json.dumps(s, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# ---------------- Plan 建立 ----------------\n",
    "def build_plan_from_lines(lines):\n",
    "    scenes=[]\n",
    "    for i,line in enumerate(lines, start=1):\n",
    "        scenes.append({\n",
    "            \"number\": i,\n",
    "            \"subtitle_text\": line,\n",
    "            \"raw_text\": line,\n",
    "            \"ai_prompt\": line,\n",
    "            \"audio_file\": None,\n",
    "            \"image_file\": None,\n",
    "            \"flags\": {\"enable_ducking\": True},\n",
    "            \"tts\": {\"voice\":\"alloy\",\"language\":\"zh-TW\"},\n",
    "            \"transition\": {\"type\":\"none\",\"duration\":0.0},\n",
    "            \"duration_override\": None\n",
    "        })\n",
    "    plan = {\n",
    "        \"project_title\": \"OneStepYamlEditor\",\n",
    "        \"date\": datetime.datetime.now().strftime(\"%Y%m%d\"),\n",
    "        \"version\": 1,\n",
    "        \"global\": {\n",
    "            \"resolution\":[1920,1080],\n",
    "            \"fps\":25,\n",
    "            \"subtitle\":{\n",
    "                \"font_family\":\"Arial\",\"font_size\":48,\"outline\":3,\"shadow\":0,\n",
    "                \"color\":\"#FFFFFF\",\"align\":\"bottom-center\",\"margin_v\":60\n",
    "            },\n",
    "            \"loudnorm\":{\"target_i\":LOUDNORM_I,\"target_tp\":LOUDNORM_TP,\"target_lra\":LOUDNORM_LRA,\"mode\":\"two-pass\"},\n",
    "            \"music\":{\"file\":None,\"gain_db\":-8,\"ducking\":{\"threshold\":0.1,\"ratio\":8.0,\"attack_ms\":10,\"release_ms\":250}},\n",
    "            \"transitions\":{\"default_type\":\"none\",\"default_duration\":0.0}\n",
    "        },\n",
    "        \"scenes\": scenes\n",
    "    }\n",
    "    return plan\n",
    "\n",
    "def plan_scene_count(plan):\n",
    "    sc = plan.get(\"scenes\",[])\n",
    "    return len(sc) if isinstance(sc, list) else 0\n",
    "\n",
    "def write_handshake_lock(plan_yaml_text: str, scenes_count: int):\n",
    "    md5 = _md5_text(plan_yaml_text)\n",
    "    hs = {\"filename\": PLAN_CURRENT, \"scenes\": scenes_count, \"md5\": md5, \"saved_at\": datetime.datetime.now().isoformat(timespec=\"seconds\")}\n",
    "    atomic_write_text(main_dir/HANDSHAKE_NAME, json.dumps(hs, ensure_ascii=False, indent=2))\n",
    "    lk = {\"filename\": PLAN_CURRENT, \"locked_at\": datetime.datetime.now().isoformat(timespec=\"seconds\")}\n",
    "    atomic_write_text(main_dir/LOCK_NAME, json.dumps(lk, ensure_ascii=False, indent=2))\n",
    "    return md5\n",
    "\n",
    "def backup_plan_yaml(plan_text: str):\n",
    "    stamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    (main_dir / f\"plan_{stamp}.yaml\").write_text(plan_text, encoding=\"utf-8\")\n",
    "    return f\"plan_{stamp}.yaml\"\n",
    "\n",
    "# ---------------- 字幕工具 ----------------\n",
    "def _hex_to_ass_color(hx: str):\n",
    "    try:\n",
    "        s=hx.strip()\n",
    "        if s.startswith(\"#\"): s=s[1:]\n",
    "        r=int(s[0:2],16); g=int(s[2:4],16); b=int(s[4:6],16)\n",
    "        return f\"&H{b:02X}{g:02X}{r:02X}&\"\n",
    "    except:\n",
    "        return \"&HFFFFFF&\"\n",
    "\n",
    "def _seconds_to_ass(sec: float):\n",
    "    sec=max(0.0, float(sec))\n",
    "    h=int(sec//3600); m=int((sec%3600)//60); s=int(sec%60); cs=int(round((sec-int(sec))*100))\n",
    "    return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n",
    "\n",
    "def _seconds_to_srt(sec: float):\n",
    "    sec=max(0.0, float(sec))\n",
    "    h=int(sec//3600); m=int((sec%3600)//60); s=int(sec%60); ms=int(round((sec-int(sec))*1000))\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n",
    "\n",
    "def build_subtitle_events(plan):\n",
    "    events=[]; t=0.0\n",
    "    for sc in plan.get(\"scenes\",[]):\n",
    "        text=sc.get(\"subtitle_text\") or sc.get(\"raw_text\") or \"\"\n",
    "        dur=None\n",
    "        af=sc.get(\"audio_file\")\n",
    "        if af and (main_dir/af).exists():\n",
    "            dur=_ffprobe_duration(main_dir/af)\n",
    "        if dur is None:\n",
    "            dur=sc.get(\"duration_override\") or DEFAULT_FALLBACK_DURATION\n",
    "        start=t; end=t+dur\n",
    "        events.append({\"scene\":sc.get(\"number\",0),\"start\":start,\"end\":end,\"text\":text})\n",
    "        t=end\n",
    "    return events\n",
    "\n",
    "def write_ass(events, plan, out_path=None, settings=None):\n",
    "    sub_cfg=plan.get(\"global\",{}).get(\"subtitle\",{}) or {}\n",
    "    font=sub_cfg.get(\"font_family\",\"Arial\"); size=int(sub_cfg.get(\"font_size\",48))\n",
    "    outline=int(sub_cfg.get(\"outline\",3)); shadow=int(sub_cfg.get(\"shadow\",0))\n",
    "    color=_hex_to_ass_color(sub_cfg.get(\"color\",\"#FFFFFF\"))\n",
    "    align_map={'bottom-left':1,'bottom-center':2,'bottom-right':3,'middle-left':4,'middle-center':5,'middle-right':6,'top-left':7,'top-center':8,'top-right':9}\n",
    "    align=align_map.get(sub_cfg.get(\"align\",\"bottom-center\"),2)\n",
    "    margin_v=int(sub_cfg.get(\"margin_v\",60))\n",
    "    w,h=plan.get(\"global\",{}).get(\"resolution\",[1920,1080])\n",
    "    scale_pct = 125\n",
    "    if settings and isinstance(settings, dict):\n",
    "        scale_pct = int((settings.get(\"subs\") or {}).get(\"scale_pct\", scale_pct))\n",
    "    scale_x=scale_pct; scale_y=scale_pct\n",
    "\n",
    "    header=textwrap.dedent(f\"\"\"\\\n",
    "    [Script Info]\n",
    "    PlayResX: {w}\n",
    "    PlayResY: {h}\n",
    "    ScaledBorderAndShadow: yes\n",
    "\n",
    "    [V4+ Styles]\n",
    "    Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
    "    Style: Default,{font},{size},{color},&H000000FF,&H00000000,&H00000000,0,0,0,0,{scale_x},{scale_y},0,0,1,{outline},{shadow},{align},30,30,{margin_v},1\n",
    "\n",
    "    [Events]\n",
    "    Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
    "    \"\"\")\n",
    "    lines=[header]\n",
    "    for e in events:\n",
    "        start_str=_seconds_to_ass(e['start']); end_str=_seconds_to_ass(e['end'])\n",
    "        text_raw=e.get('text') or ''\n",
    "        text_ass=text_raw.replace('\\n', r'\\N')\n",
    "        lines.append(f\"Dialogue: 0,{start_str},{end_str},Default,,0,0,0,,{text_ass}\\n\")\n",
    "    if out_path is None:\n",
    "        out_path = main_dir / \"combined.ass\"\n",
    "    else:\n",
    "        out_path = Path(out_path)\n",
    "    out_path.write_text(''.join(lines),encoding=\"utf-8\")\n",
    "    return out_path\n",
    "\n",
    "def write_srt(events, out_path: Path):\n",
    "    out=[]\n",
    "    for i,e in enumerate(events, start=1):\n",
    "        start_str=_seconds_to_srt(e['start']); end_str=_seconds_to_srt(e['end'])\n",
    "        text_raw=e.get('text') or ''\n",
    "        out.append(f\"{i}\\n{start_str} --> {end_str}\\n{text_raw}\\n\\n\")\n",
    "    out_path.write_text('.'.join(out).replace('..','.'),encoding=\"utf-8\") if False else out_path.write_text(''.join(out),encoding=\"utf-8\")\n",
    "    return out_path\n",
    "\n",
    "# ---------------- 音訊正規化 ----------------\n",
    "def validate_audio(audio_path: Path, fallback_sec=3.0) -> Path:\n",
    "    audio_path=Path(audio_path)\n",
    "    if not audio_path.exists() or audio_path.stat().st_size==0:\n",
    "        sil=audio_path.with_suffix(\".silence.wav\")\n",
    "        _run([\"ffmpeg\",\"-y\",\"-f\",\"lavfi\",\"-i\",\"anullsrc=r=48000:cl=stereo\",\"-t\",f\"{fallback_sec:.3f}\",\n",
    "              \"-c:a\",\"pcm_s16le\", str(sil)])\n",
    "        return sil\n",
    "    res=_run([\"ffmpeg\",\"-v\",\"error\",\"-i\",str(audio_path),\"-f\",\"null\",\"-\"], capture=True)\n",
    "    if res.returncode!=0:\n",
    "        sil=audio_path.with_suffix(\".silence.wav\")\n",
    "        _run([\"ffmpeg\",\"-y\",\"-f\",\"lavfi\",\"-i\",\"anullsrc=r=48000:cl=stereo\",\"-t\",f\"{fallback_sec:.3f}\",\n",
    "              \"-c:a\",\"pcm_s16le\", str(sil)])\n",
    "        return sil\n",
    "    return audio_path\n",
    "\n",
    "def loudnorm_two_pass(in_path: Path, out_path: Path) -> bool:\n",
    "    probe=_run([\"ffmpeg\",\"-i\",str(in_path),\"-af\",\n",
    "                f\"loudnorm=I={LOUDNORM_I}:TP={LOUDNORM_TP}:LRA={LOUDNORM_LRA}:print_format=json\",\n",
    "                \"-f\",\"null\",\"-\"], capture=True)\n",
    "    blob=(probe.stdout or \"\")+(probe.stderr or \"\")\n",
    "    m=re.search(r'\\{[\\s\\S]*?\\}', blob)\n",
    "    if not m: return False\n",
    "    try:\n",
    "        data=json.loads(m.group(0))\n",
    "        filt=(f\"loudnorm=I={LOUDNORM_I}:TP={LOUDNORM_TP}:LRA={LOUDNORM_LRA}:\"\n",
    "              f\"input_i={data['input_i']}:input_tp={data['input_tp']}:input_lra={data['input_lra']}:\"\n",
    "              f\"input_thresh={data['input_thresh']}:offset={data['target_offset']}:linear=true:print_format=summary\")\n",
    "        res=_run([\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-af\",filt,str(out_path)], capture=True)\n",
    "        return res.returncode==0 and out_path.exists() and out_path.stat().st_size>0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def loudnorm_one_pass(in_path: Path, out_path: Path) -> bool:\n",
    "    res=_run([\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-af\",\n",
    "              f\"loudnorm=I={LOUDNORM_I}:TP={LOUDNORM_TP}:LRA={LOUDNORM_LRA}\", str(out_path)], capture=True)\n",
    "    return res.returncode==0 and out_path.exists() and out_path.stat().st_size>0\n",
    "\n",
    "def process_scene_audio_return_final(sc, fallback_sec=DEFAULT_FALLBACK_DURATION) -> Path:\n",
    "    num=sc.get(\"number\"); af=sc.get(\"audio_file\")\n",
    "    if not af or not (main_dir/af).exists():\n",
    "        silent=main_dir/f\"scene_{num:03d}_silent.wav\"\n",
    "        _run([\"ffmpeg\",\"-y\",\"-f\",\"lavfi\",\"-i\",\"anullsrc=r=48000:cl=stereo\",\"-t\",f\"{fallback_sec:.3f}\",\n",
    "              \"-c:a\",\"pcm_s16le\", str(silent)])\n",
    "        af=silent.name; sc[\"audio_file\"]=af\n",
    "    src=validate_audio(main_dir/af, fallback_sec=fallback_sec)\n",
    "    norm=main_dir/f\"scene_{num:03d}_norm.wav\"\n",
    "    ok=loudnorm_two_pass(src, norm)\n",
    "    if not ok: ok=loudnorm_one_pass(src, norm)\n",
    "    final_audio=norm if ok else src\n",
    "    return validate_audio(final_audio, fallback_sec=fallback_sec)\n",
    "\n",
    "# ---------------- TTS ----------------\n",
    "def tts_generate(text: str, out_path: Path, settings: dict, default_voice=\"alloy\"):\n",
    "    prov = (settings.get(\"tts\") or {}).get(\"provider\",\"OPENAI\")\n",
    "    if prov==\"OPENAI\":\n",
    "        o = (settings[\"tts\"]).get(\"openai\",{})\n",
    "        voice=o.get(\"voice\", default_voice)\n",
    "        model=o.get(\"model\",\"tts-1\")\n",
    "        fmt=o.get(\"format\",\"mp3\")\n",
    "        return tts_openai(text, out_path.with_suffix(f\".{fmt}\"), voice=voice, model=model)\n",
    "    elif prov==\"AZURE\":\n",
    "        ax = (settings[\"tts\"]).get(\"azure\",{})\n",
    "        voice=ax.get(\"voice\",\"zh-TW-HsiaoChenNeural\")\n",
    "        fmt=ax.get(\"format\",\"audio-24khz-48kbitrate-mono-mp3\")\n",
    "        rate_pct=int(ax.get(\"rate_pct\",0)); pitch_pct=int(ax.get(\"pitch_pct\",0))\n",
    "        region=ax.get(\"region\") or AZURE_TTS_REGION\n",
    "        return tts_azure(text, out_path.with_suffix(\".mp3\"), voice=voice, rate_pct=rate_pct, pitch_pct=pitch_pct, fmt=fmt, region=region)\n",
    "    elif prov==\"MINIMAX\":\n",
    "        mm = (settings[\"tts\"]).get(\"minimax\",{})\n",
    "        model=mm.get(\"model\",\"speech-01\"); voice_id=mm.get(\"voice_id\",\"female-1\")\n",
    "        fmt=mm.get(\"format\",\"mp3\")\n",
    "        return tts_minimax(text, out_path.with_suffix(f\".{fmt}\"), model=model, voice_id=voice_id)\n",
    "    else:\n",
    "        return False, f\"未知 TTS 供應商: {prov}\"\n",
    "\n",
    "def tts_openai(text: str, out_path: Path, voice=\"alloy\", model=\"tts-1\"):\n",
    "    if not OPENAI_API_KEY:\n",
    "        return False,\"缺少 OPENAI_API_KEY\"\n",
    "    import requests\n",
    "    try:\n",
    "        url=\"https://api.openai.com/v1/audio/speech\"\n",
    "        headers={\"Authorization\":f\"Bearer {OPENAI_API_KEY}\",\"Content-Type\":\"application/json\"}\n",
    "        if OPENAI_ORG_ID: headers[\"OpenAI-Organization\"]=OPENAI_ORG_ID\n",
    "        payload={\"model\":model,\"voice\":voice,\"input\":text or \"\",\"response_format\":out_path.suffix[1:] or \"mp3\"}\n",
    "        r=requests.post(url,headers=headers,json=payload,timeout=180)\n",
    "        if r.status_code!=200:\n",
    "            return False,f\"{r.status_code} {r.text[:200]}\"\n",
    "        out_path.write_bytes(r.content)\n",
    "        return True,\"OK\"\n",
    "    except Exception as e:\n",
    "        return False,f\"Exception {e}\"\n",
    "\n",
    "def tts_azure(text: str, out_path: Path, voice=\"zh-TW-HsiaoChenNeural\", rate_pct=0, pitch_pct=0, fmt=\"audio-24khz-48kbitrate-mono-mp3\", region=\"\"):\n",
    "    if not AZURE_TTS_KEY or not (region or AZURE_TTS_REGION):\n",
    "        return False,\"缺少 AZURE_TTS_KEY / AZURE_TTS_REGION\"\n",
    "    import requests\n",
    "    try:\n",
    "        endpoint=f\"https://{region}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "        ssml=f\"\"\"<speak version='1.0' xml:lang='zh-TW'>\n",
    "  <voice name='{voice}'><prosody rate='{rate_pct:+d}%' pitch='{pitch_pct:+d}%'>\n",
    "    {text or \"\"}\n",
    "  </prosody></voice>\n",
    "</speak>\"\"\"\n",
    "        headers={\n",
    "            \"Ocp-Apim-Subscription-Key\": AZURE_TTS_KEY,\n",
    "            \"Content-Type\": \"application/ssml+xml\",\n",
    "            \"X-Microsoft-OutputFormat\": fmt,\n",
    "            \"User-Agent\": \"OneStepYamlEditor\"\n",
    "        }\n",
    "        r=requests.post(endpoint, headers=headers, data=ssml.encode(\"utf-8\"), timeout=180)\n",
    "        if r.status_code!=200:\n",
    "            return False,f\"{r.status_code} {r.text[:200]}\"\n",
    "        out_path.write_bytes(r.content)\n",
    "        return True,\"OK\"\n",
    "    except Exception as e:\n",
    "        return False,f\"Exception {e}\"\n",
    "\n",
    "def tts_minimax(text: str, out_path: Path, model=\"speech-01\", voice_id=\"female-1\"):\n",
    "    if not MINIMAX_API_KEY:\n",
    "        return False,\"缺少 MINIMAX_API_KEY\"\n",
    "    return False,\"Minimax TTS 尚未實作（請提供 API 規格）\"\n",
    "\n",
    "# ---------------- 片段組合 ----------------\n",
    "def make_scene_clip(image_file, audio_file, duration, w, h, fps, out_path: Path):\n",
    "    \"\"\"Create scene clip ensuring image/video duration strictly matches audio duration to prevent black frames.\"\"\"\n",
    "    out_path=Path(out_path)\n",
    "    audio_p=main_dir/audio_file if isinstance(audio_file,str) else Path(audio_file)\n",
    "    img_p=(main_dir/image_file) if (image_file and isinstance(image_file,str)) else None\n",
    "    \n",
    "    # Verify actual audio duration for strict matching\n",
    "    actual_duration = duration\n",
    "    if audio_p and audio_p.exists():\n",
    "        probe_dur = _ffprobe_duration(audio_p)\n",
    "        if probe_dur and probe_dur > 0.1:\n",
    "            actual_duration = probe_dur\n",
    "\n",
    "    def cmd_aac(shortest=True, use_color=False):\n",
    "        # Use -shortest AND explicit -t to ensure strict duration matching and prevent black frames\n",
    "        base=([\"-f\",\"lavfi\",\"-t\",f\"{actual_duration:.3f}\",\"-i\",f\"color=black:s={w}x{h}:r={fps}\"] if use_color\n",
    "              else [\"-loop\",\"1\",\"-framerate\",str(fps),\"-t\",f\"{actual_duration:.3f}\",\"-i\",str(img_p)])\n",
    "        return ([\"ffmpeg\",\"-y\"]+base+[\"-i\",str(audio_p)]+\n",
    "                [\"-t\",f\"{actual_duration:.3f}\",\"-shortest\"]+  # Always use both for strict sync\n",
    "                ([\"-filter:v\",f\"scale={w}:{h}:force_original_aspect_ratio=decrease,pad={w}:{h}:(ow-iw)/2:(oh-ih)/2\"] if not use_color else [])+\n",
    "                [\"-r\",str(fps),\"-c:v\",\"libx264\",\"-pix_fmt\",\"yuv420p\",\"-c:a\",\"aac\",\"-b:a\",\"192k\",\"-movflags\",\"+faststart\",str(out_path)])\n",
    "\n",
    "    def cmd_mp3(use_color=False):\n",
    "        # Add -shortest to ensure video doesn't extend beyond audio\n",
    "        base=([\"-f\",\"lavfi\",\"-i\",f\"color=black:s={w}x{h}:r={fps}\"] if use_color\n",
    "              else [\"-loop\",\"1\",\"-framerate\",str(fps),\"-i\",str(img_p)])\n",
    "        return ([\"ffmpeg\",\"-y\"]+base+[\"-i\",str(audio_p),\"-t\",f\"{actual_duration:.3f}\",\"-shortest\"]+\n",
    "                ([\"-filter:v\",f\"scale={w}:{h}:force_original_aspect_ratio=decrease,pad={w}:{h}:(ow-iw)/2:(oh-ih)/2\"] if not use_color else [])+\n",
    "                [\"-r\",str(fps),\"-c:v\",\"libx264\",\"-pix_fmt\",\"yuv420p\",\"-c:a\",\"libmp3lame\",\"-q:a\",\"3\",\"-movflags\",\"+faststart\",str(out_path)])\n",
    "\n",
    "    def cmd_last():\n",
    "        return [\"ffmpeg\",\"-y\",\"-f\",\"lavfi\",\"-t\",f\"{duration:.3f}\",\"-i\",f\"color=black:s={w}x{h}:r={fps}\",\n",
    "                \"-f\",\"lavfi\",\"-t\",f\"{duration:.3f}\",\"-i\",\"anullsrc=r=48000:cl=stereo\",\n",
    "                \"-r\",str(fps),\"-c:v\",\"libx264\",\"-pix_fmt\",\"yuv420p\",\"-c:a\",\"aac\",\"-b:a\",\"192k\",\"-movflags\",\"+faststart\",str(out_path)]\n",
    "\n",
    "    attempts=[]\n",
    "    if img_p and img_p.exists():\n",
    "        attempts.append((\"A_aac_shortest\", cmd_aac(shortest=True, use_color=False)))\n",
    "        attempts.append((\"B_aac_fixed_t\",  cmd_aac(shortest=False, use_color=False)))\n",
    "        attempts.append((\"C_mp3_fixed_t\",  cmd_mp3(use_color=False)))\n",
    "    attempts.append((\"D_mp3_color_t\",     cmd_mp3(use_color=True)))\n",
    "    attempts.append((\"E_synthetic\",       cmd_last()))\n",
    "\n",
    "    for label,cmd in attempts:\n",
    "        res=_run(cmd, capture=True)\n",
    "        if res.returncode==0 and out_path.exists() and out_path.stat().st_size>0:\n",
    "            return True,label\n",
    "    return False,\"failed\"\n",
    "\n",
    "# ---------------- 內建(簡易) 飄落（drawtext） ----------------\n",
    "def builtin_simple_node(kind: str, W: int, H: int, fps: int, density: int, size_px: int, speed: int, color: str, layer_index: int, opacity: float = 1.0):\n",
    "    glyph = \"❄\" if kind==\"snow\" else (\"│\" if kind==\"rain\" else \"🍁\")\n",
    "    sway_amp = 40 if kind==\"snow\" else (8 if kind==\"rain\" else 80)\n",
    "    nodes = [f\"color=c=black@0.0:s={W}x{H}:r={fps},format=rgba\"]\n",
    "    n_items = max(1, int(density))\n",
    "    spd = max(1, int(speed))\n",
    "    a = max(0.0, min(1.0, float(opacity)))\n",
    "    for i in range(n_items):\n",
    "        xi = f\"(w/{n_items})*{i}+{sway_amp}*sin(t*0.8+{i})\"\n",
    "        yi = f\"mod(t*{spd} + (h/{n_items})*{i}, h)\"\n",
    "        nodes.append(\n",
    "            f\"drawtext=text='{glyph}':fontcolor={color}:fontsize={int(size_px)}:x='{xi}':y='{yi}':alpha={a}\"\n",
    "        )\n",
    "    out_label = f\"ovb{layer_index}\"\n",
    "    graph = \",\".join(nodes) + f\"[{out_label}]\"\n",
    "    return graph, out_label\n",
    "\n",
    "# ---------------- 內建(進階) 透明特效（生成透明 VP9 WebM並快取） ----------------\n",
    "def _write_default_texture(kind: str) -> Path:\n",
    "    # 用 PIL 生成簡單圖樣（免外部檔）\n",
    "    from PIL import Image, ImageDraw\n",
    "    p = main_dir / f\"_adv_tex_{kind}.png\"\n",
    "    if p.exists():\n",
    "        return p\n",
    "    img = Image.new(\"RGBA\",(128,128),(255,255,255,0))\n",
    "    d = ImageDraw.Draw(img)\n",
    "    if kind==\"snow\":\n",
    "        # 簡單六角雪花\n",
    "        cx, cy, r = 64, 64, 40\n",
    "        for ang in range(0,360,60):\n",
    "            x = cx + r*math.cos(math.radians(ang))\n",
    "            y = cy + r*math.sin(math.radians(ang))\n",
    "            d.line([(cx,cy),(x,y)], fill=(255,255,255,220), width=6)\n",
    "    elif kind==\"rain\":\n",
    "        d.line([(64,8),(96,120)], fill=(255,255,255,220), width=10)\n",
    "    else:\n",
    "        # 葉片菱形\n",
    "        d.polygon([(64,8),(120,64),(64,120),(8,64)], fill=(255,180,0,220))\n",
    "    img.save(p)\n",
    "    return p\n",
    "\n",
    "def _ensure_adv_overlay_clip(layer_idx: int, adv_cfg: dict, base_w: int, base_h: int, fps: int, opacity: float, profile: dict) -> (Path, tuple):\n",
    "    \"\"\"\n",
    "    依設定生成/重用透明 WebM，回傳 (clip_path, (gen_w, gen_h))\n",
    "    若 profile['adv_half_res'] 為 True，則以半尺寸生成（疊時會放大）\n",
    "    VP9 參數取自 profile['vp9']\n",
    "    \"\"\"\n",
    "    half = bool(profile.get(\"adv_half_res\", True))\n",
    "    gen_w = max(2, base_w//2) if half else base_w\n",
    "    gen_h = max(2, base_h//2) if half else base_h\n",
    "\n",
    "    vp9 = profile.get(\"vp9\", {\"crf\":32,\"cpu_used\":8,\"tile_columns\":2,\"row_mt\":1,\"auto_alt_ref\":0})\n",
    "    crf = int(vp9.get(\"crf\",32)); cpu = int(vp9.get(\"cpu_used\",8))\n",
    "    tiles = int(vp9.get(\"tile_columns\",2)); rowmt = int(vp9.get(\"row_mt\",1)); aarf = int(vp9.get(\"auto_alt_ref\",0))\n",
    "\n",
    "    # 參數雜湊（生成快取）\n",
    "    key = {\"w\":gen_w,\"h\":gen_h,\"fps\":fps,\"adv\":adv_cfg,\"opa\":round(float(opacity),3),\"vp9\":vp9,\"ver\":\"1.1\"}\n",
    "    hid = _md5_text(json.dumps(key, sort_keys=True))\n",
    "    out_path = main_dir / f\"_adv_overlay_L{layer_idx}_{hid[:10]}.webm\"\n",
    "    meta_path= out_path.with_suffix(\".json\")\n",
    "    if out_path.exists() and meta_path.exists():\n",
    "        try:\n",
    "            m = json.loads(meta_path.read_text(encoding=\"utf-8\"))\n",
    "            if m.get(\"hash\")==hid:\n",
    "                return out_path, (gen_w, gen_h)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 準備材質\n",
    "    kind = (adv_cfg.get(\"kind\") or \"snow\").lower()\n",
    "    tex_file = adv_cfg.get(\"texture_file\") or \"\"\n",
    "    tex_path = Path(tex_file) if tex_file else _write_default_texture(\"snow\" if kind==\"snow\" else (\"rain\" if kind==\"rain\" else \"leaves\"))\n",
    "    if not tex_path.exists():\n",
    "        tex_path = _write_default_texture(\"snow\" if kind==\"snow\" else (\"rain\" if kind==\"rain\" else \"leaves\"))\n",
    "\n",
    "    # 生成逐幀 PNG\n",
    "    loop_sec = max(2, int(adv_cfg.get(\"loop_sec\",8)))\n",
    "    frames = loop_sec * fps\n",
    "    from PIL import Image, ImageDraw\n",
    "    rnd = random.Random(int(adv_cfg.get(\"seed\",1337)))\n",
    "    N = max(1, int(adv_cfg.get(\"density\",60)))\n",
    "    size_min = max(6, int(adv_cfg.get(\"size_min\",20)))\n",
    "    size_max = max(size_min+1, int(adv_cfg.get(\"size_max\",64)))\n",
    "    spd_min  = max(10, int(adv_cfg.get(\"speed_min\",60)))\n",
    "    spd_max  = max(spd_min+1, int(adv_cfg.get(\"speed_max\",180)))\n",
    "    drift    = float(adv_cfg.get(\"drift\",60))\n",
    "    turb     = float(adv_cfg.get(\"turbulence\",25))\n",
    "    rot_min  = float(adv_cfg.get(\"rotation_min\",-90))\n",
    "    rot_max  = float(adv_cfg.get(\"rotation_max\", 90))\n",
    "    layer_split = adv_cfg.get(\"layers\", {\"near\":0.4,\"mid\":0.35,\"far\":0.25})\n",
    "    split = [(\"near\", float(layer_split.get(\"near\",0.4))),\n",
    "             (\"mid\",  float(layer_split.get(\"mid\",0.35))),\n",
    "             (\"far\",  float(layer_split.get(\"far\",0.25)))]\n",
    "    ssum = sum(v for _,v in split) or 1.0\n",
    "    split = [(k, v/ssum) for k,v in split]\n",
    "    depth_mul = {\"near\":1.15, \"mid\":1.0, \"far\":0.85}\n",
    "    speed_mul = {\"near\":1.25, \"mid\":1.0, \"far\":0.75}\n",
    "    drift_mul = {\"near\":1.0,  \"mid\":0.8, \"far\":0.6}\n",
    "\n",
    "    tex_img = Image.open(tex_path).convert(\"RGBA\") if kind!=\"rain\" else None\n",
    "\n",
    "    particles=[]\n",
    "    for i in range(N):\n",
    "        r = rnd.random()\n",
    "        acc=0.0; group=\"far\"\n",
    "        for k,p in split:\n",
    "            acc+=p\n",
    "            if r<=acc:\n",
    "                group=k; break\n",
    "        sx = rnd.uniform(0, gen_w)\n",
    "        sy = rnd.uniform(0, gen_h)\n",
    "        sz = rnd.randint(size_min, size_max) * depth_mul[group]\n",
    "        sp = rnd.uniform(spd_min, spd_max) * speed_mul[group]\n",
    "        dr = drift * drift_mul[group]\n",
    "        rs = rnd.uniform(rot_min, rot_max)  # deg/sec\n",
    "        ph = rnd.uniform(0, math.tau)\n",
    "        tb = rnd.uniform(0.3,1.2) * turb\n",
    "        particles.append({\"x\":sx,\"y\":sy,\"size\":sz,\"speed\":sp,\"drift\":dr,\"rotspd\":rs,\"phase\":ph,\"turb\":tb,\"group\":group,\"tex\":tex_img})\n",
    "\n",
    "    tmp_dir = Path(tempfile.mkdtemp(prefix=f\"advL{layer_idx}_\", dir=str(main_dir)))\n",
    "    try:\n",
    "        for fi in range(frames):\n",
    "            t = fi / fps\n",
    "            canvas = Image.new(\"RGBA\",(gen_w,gen_h),(0,0,0,0))\n",
    "            draw = ImageDraw.Draw(canvas)\n",
    "            for p in particles:\n",
    "                p[\"y\"] = (p[\"y\"] + p[\"speed\"]/fps) % gen_h\n",
    "                x = (p[\"x\"] + p[\"drift\"]*math.sin(0.8*t + p[\"phase\"]) +\n",
    "                     p[\"turb\"]*math.sin(1.7*t + p[\"phase\"]*1.23))\n",
    "                y = p[\"y\"]\n",
    "                if kind==\"rain\":\n",
    "                    length = max(8, int(p[\"size\"]*1.5))\n",
    "                    dx = int(p[\"drift\"]*0.15)\n",
    "                    draw.line([(x, y), (x+dx, y+length)], fill=(255,255,255,int(255*opacity)), width=max(1, int(p[\"size\"]*0.08)))\n",
    "                else:\n",
    "                    tex = p[\"tex\"]\n",
    "                    sz  = max(6, int(p[\"size\"]))\n",
    "                    stamp = tex.resize((sz,sz), Image.LANCZOS)\n",
    "                    angle = (p[\"rotspd\"]*t) % 360.0\n",
    "                    stamp_r = stamp.rotate(angle, resample=Image.BICUBIC, expand=True)\n",
    "                    if opacity < 1.0:\n",
    "                        a_chan = stamp_r.split()[3]\n",
    "                        a_chan = a_chan.point(lambda v: int(v*opacity))\n",
    "                        stamp_r.putalpha(a_chan)\n",
    "                    cx = int(x - stamp_r.size[0]//2)\n",
    "                    cy = int(y - stamp_r.size[1]//2)\n",
    "                    canvas.alpha_composite(stamp_r, (cx, cy))\n",
    "            canvas.save(tmp_dir / f\"f_{fi:06d}.png\", \"PNG\")\n",
    "\n",
    "        # 透明 VP9\n",
    "        cmd = [\"ffmpeg\",\"-y\",\"-framerate\",str(fps),\"-i\",str(tmp_dir/\"f_%06d.png\"),\n",
    "               \"-c:v\",\"libvpx-vp9\",\"-pix_fmt\",\"yuva420p\",\"-b:v\",\"0\",\"-crf\",str(crf),\n",
    "               \"-cpu-used\",str(cpu),\"-row-mt\",str(rowmt),\"-tile-columns\",str(tiles),\n",
    "               \"-auto-alt-ref\",str(aarf),\n",
    "               str(out_path)]\n",
    "        r = _run(cmd, capture=True)\n",
    "        if r.returncode != 0 or not out_path.exists() or out_path.stat().st_size==0:\n",
    "            raise RuntimeError(\"ffmpeg 生成透明 WebM 失敗\")\n",
    "\n",
    "        meta = {\"hash\":hid,\"created\":datetime.datetime.now().isoformat(timespec=\"seconds\"),\n",
    "                \"w\":gen_w,\"h\":gen_h,\"fps\":fps,\"frames\":frames,\"kind\":kind}\n",
    "        meta_path.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "        return out_path, (gen_w, gen_h)\n",
    "    finally:\n",
    "        try:\n",
    "            for p in tmp_dir.glob(\"*.png\"): p.unlink(missing_ok=True)\n",
    "            tmp_dir.rmdir()\n",
    "        except: pass\n",
    "\n",
    "# ---------------- 後製（濾鏡 + Overlay） ----------------\n",
    "def build_filter_chain_and_inputs(base_w, base_h, settings: dict, base_fps=25):\n",
    "    post = (settings.get(\"post\") or {})\n",
    "    prof = settings.get(\"profile\") or {}\n",
    "    filters_base = []\n",
    "    if (post.get(\"color\") or {}).get(\"enabled\", False):\n",
    "        c = post[\"color\"]; filters_base.append(f\"eq=brightness={float(c.get('brightness',0.0))}:contrast={float(c.get('contrast',1.0))}:saturation={float(c.get('saturation',1.0))}\")\n",
    "    if (post.get(\"denoise\") or {}).get(\"enabled\", False):\n",
    "        p = (post[\"denoise\"].get(\"preset\",\"medium\") or \"medium\").lower()\n",
    "        filters_base.append(\"hqdn3d=2:1.5:3:2\" if p==\"low\" else (\"hqdn3d=8:6:12:8\" if p==\"high\" else \"hqdn3d=4:3:6:4\"))\n",
    "    if (post.get(\"sharpen\") or {}).get(\"enabled\", False):\n",
    "        amt = max(0.0, min(2.0, float(post[\"sharpen\"].get(\"amount\",0.8)))); filters_base.append(f\"unsharp=5:5:{amt}:5:5:{amt/2:.3f}\")\n",
    "    if (post.get(\"fps_interp\") or {}).get(\"enabled\", False):\n",
    "        tfps = int(post[\"fps_interp\"].get(\"fps\",60)); filters_base.append(f\"minterpolate=fps={tfps}\")\n",
    "\n",
    "    graph_parts = []\n",
    "    vcur = \"v0\"\n",
    "    graph_parts.append(f\"[0:v]{','.join(filters_base) if filters_base else 'null'}[{vcur}]\")\n",
    "\n",
    "    extra_inputs = []\n",
    "    overlay_idx_input = 1\n",
    "    overlays = post.get(\"overlays\") or []\n",
    "    simple_idx = 0\n",
    "\n",
    "    for i,ov in enumerate(overlays, start=1):\n",
    "        if not ov.get(\"enabled\", False): \n",
    "            continue\n",
    "        mode = (ov.get(\"mode\") or \"file\").lower()\n",
    "        op  = float(ov.get(\"opacity\",1.0))\n",
    "        if mode == \"builtin_simple\":\n",
    "            simple_idx += 1\n",
    "            simp = ov.get(\"simple\") or {}\n",
    "            kind = (simp.get(\"kind\") or \"snow\").lower()\n",
    "            dens = int(simp.get(\"density\",30))\n",
    "            size = int(simp.get(\"size\",48))\n",
    "            spd  = int(simp.get(\"speed\",120))\n",
    "            col  = simp.get(\"color\",\"white\")\n",
    "            gnode, outlbl = builtin_simple_node(kind, base_w, base_h, base_fps, dens, size, spd, col, simple_idx, opacity=op)\n",
    "            graph_parts.append(gnode)\n",
    "            graph_parts.append(f\"[{vcur}][{outlbl}]overlay=0:0:shortest=1[v{i}]\")\n",
    "            vcur = f\"v{i}\"\n",
    "        elif mode == \"builtin_advanced\":\n",
    "            adv = ov.get(\"advanced\") or {}\n",
    "            clip, (gen_w, gen_h) = _ensure_adv_overlay_clip(i, adv, base_w, base_h, base_fps, opacity=op, profile=prof)\n",
    "            extra_inputs += [\"-stream_loop\",\"-1\",\"-i\", str(clip)]\n",
    "            pre = []\n",
    "            if gen_w!=base_w or gen_h!=base_h:\n",
    "                pre.append(f\"scale={base_w}:{base_h}:flags=lanczos\")\n",
    "            pre_chain = \",\".join(pre) if pre else \"null\"\n",
    "            graph_parts.append(f\"[{overlay_idx_input}:v]{pre_chain}[ov{i}]\")\n",
    "            graph_parts.append(f\"[{vcur}][ov{i}]overlay=0:0:shortest=1[v{i}]\")\n",
    "            vcur = f\"v{i}\"; overlay_idx_input += 1\n",
    "        else:\n",
    "            f = (ov.get(\"file\") or \"\").strip()\n",
    "            if not f or not (main_dir/f).exists():\n",
    "                continue\n",
    "            extra_inputs += [\"-stream_loop\",\"-1\",\"-i\", str(main_dir/f)]\n",
    "            typ = (ov.get(\"type\") or \"alpha\").lower()\n",
    "            scl = bool(ov.get(\"scale_to_output\",True))\n",
    "            pre = [\"format=rgba\"]\n",
    "            if scl: pre.append(f\"scale={base_w}:{base_h}\")\n",
    "            pre_chain = \",\".join(pre)\n",
    "            if typ==\"alpha\":\n",
    "                graph_parts.append(f\"[{overlay_idx_input}:v]{pre_chain},colorchannelmixer=aa={op:.3f}[ov{i}]\")\n",
    "                graph_parts.append(f\"[{vcur}][ov{i}]overlay=0:0:shortest=1[v{i}]\"); vcur=f\"v{i}\"\n",
    "            elif typ==\"black\":\n",
    "                mode_b = (ov.get(\"black\") or {}).get(\"mode\",\"screen\").lower()\n",
    "                blend_mode = \"screen\" if mode_b==\"screen\" else \"addition\"\n",
    "                graph_parts.append(f\"[{overlay_idx_input}:v]{pre_chain}[ov{i}]\")\n",
    "                graph_parts.append(f\"[{vcur}][ov{i}]blend=all_mode={blend_mode}:all_opacity={op:.3f}[v{i}]\"); vcur=f\"v{i}\"\n",
    "            else:\n",
    "                gs = ov.get(\"greenscreen\") or {}\n",
    "                color = gs.get(\"color\",\"0x00FF00\"); sim=float(gs.get(\"similarity\",0.20)); bl=float(gs.get(\"blend\",0.10))\n",
    "                graph_parts.append(f\"[{overlay_idx_input}:v]chromakey={color}:{sim}:{bl},{pre_chain}[ov{i}]\")\n",
    "                graph_parts.append(f\"[{vcur}][ov{i}]overlay=0:0:shortest=1[v{i}]\"); vcur=f\"v{i}\"\n",
    "            overlay_idx_input += 1\n",
    "\n",
    "    vout = vcur\n",
    "    filter_complex = \";\".join(graph_parts)\n",
    "    return extra_inputs, filter_complex, vout\n",
    "\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def convert_webm_overlay_to_pngs(webm_path, png_prefix, frame_rate=25):\n",
    "    \"\"\"\n",
    "    將 webm 特效檔解出 png 幀圖，回傳 png 路徑 pattern字串與目錄\n",
    "    \"\"\"\n",
    "    webm_path = Path(webm_path)\n",
    "    png_dir = webm_path.parent / \"_overlaytemp\"\n",
    "    png_dir.mkdir(exist_ok=True)\n",
    "    png_pattern = str(png_dir / f\"{png_prefix}_%06d.png\")\n",
    "    for f in png_dir.glob(f\"{png_prefix}_*.png\"):\n",
    "        f.unlink()\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", str(webm_path),\n",
    "        \"-vf\", \"pad=ceil(iw/2)*2:ceil(ih/2)*2\",\n",
    "        png_pattern\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "    return png_pattern, png_dir\n",
    "\n",
    "def cleanup_overlay_pngs(png_dir, png_prefix):\n",
    "    for f in png_dir.glob(f\"{png_prefix}_*.png\"):\n",
    "        f.unlink()\n",
    "    try:\n",
    "        png_dir.rmdir()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def postprocess_final_video(base_plain: Path, settings: dict, out_path: Path, base_w=1920, base_h=1080, base_fps=25):\n",
    "    post = (settings.get(\"post\") or {})\n",
    "    nothing = True\n",
    "    if (post.get(\"color\") or {}).get(\"enabled\", False): nothing=False\n",
    "    if (post.get(\"denoise\") or {}).get(\"enabled\", False): nothing=False\n",
    "    if (post.get(\"sharpen\") or {}).get(\"enabled\", False): nothing=False\n",
    "    if (post.get(\"fps_interp\") or {}).get(\"enabled\", False): nothing=False\n",
    "    for ov in (post.get(\"overlays\") or []):\n",
    "        if ov.get(\"enabled\", False): nothing=False\n",
    "    if nothing:\n",
    "        shutil.copyfile(base_plain, out_path); return True, \"copy\"\n",
    "\n",
    "    extra_inputs, fc, vout = build_filter_chain_and_inputs(base_w, base_h, settings, base_fps=base_fps)\n",
    "\n",
    "    # --- 新增判斷：若唯一 overlay 為 .webm，則轉成 png 疊圖 ---\n",
    "    # 只補單一 webm overlay（如有多層可再遞迴；現在補你特效全黑問題）\n",
    "    webm_overlay = None\n",
    "    for e in extra_inputs:\n",
    "        if isinstance(e, str) and e.lower().endswith(\".webm\"):\n",
    "            webm_overlay = Path(e)\n",
    "            break\n",
    "\n",
    "    if webm_overlay and \"overlay\" in fc:\n",
    "        # (1) 先拆 webm 成 png\n",
    "        png_pattern, png_dir = convert_webm_overlay_to_pngs(webm_overlay, \"adv_overlay\", frame_rate=base_fps)\n",
    "        # (2) 用 png 幀序列疊圖\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\", \"-i\", str(base_plain),\n",
    "            \"-framerate\", str(base_fps), \"-i\", png_pattern,\n",
    "            \"-filter_complex\", \"[0:v][1:v]overlay=0:0:shortest=1[v1]\",\n",
    "            \"-map\", \"[v1]\", \"-map\", \"0:a?\", \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\", \"-c:a\", \"aac\", \"-movflags\", \"+faststart\", str(out_path)\n",
    "        ]\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        cleanup_overlay_pngs(png_dir, \"adv_overlay\")\n",
    "        ok = (res.returncode==0 and out_path.exists() and out_path.stat().st_size>0)\n",
    "        return ok, (res.stderr or \"\")[-400:] if not ok else \"ok\"\n",
    "    else:\n",
    "        # 沒有 webm overlay, 走原本路徑\n",
    "        cmd = [\"ffmpeg\",\"-y\",\"-i\",str(base_plain)] + extra_inputs + [\n",
    "            \"-filter_complex\", fc, \"-map\", f\"[{vout}]\", \"-map\", \"0:a?\",\"-c:v\",\"libx264\",\"-pix_fmt\",\"yuv420p\",\"-c:a\",\"aac\",\"-movflags\",\"+faststart\", str(out_path)\n",
    "        ]\n",
    "        res=_run(cmd, capture=True)\n",
    "        ok = (res.returncode==0 and out_path.exists() and out_path.stat().st_size>0)\n",
    "        return ok, (res.stderr or \"\")[-400:] if not ok else \"ok\"\n",
    "\n",
    "# ---------------- 字幕硬燒/軟字幕 ----------------\n",
    "def _double_escape_drive_colon(posix: str) -> str:\n",
    "    if os.name != \"nt\": return posix\n",
    "    if re.match(r'^[A-Za-z]:/', posix):\n",
    "        return posix[0] + r'\\\\:/' + posix[3:]\n",
    "    return posix\n",
    "def _double_escape_path(p: Path) -> str:\n",
    "    return _double_escape_drive_colon(p.as_posix())\n",
    "def has_subtitles_filter():\n",
    "    r=_run([\"ffmpeg\",\"-filters\"], capture=True); blob=(r.stdout or \"\")+(r.stderr or \"\"); return \"subtitles\" in blob\n",
    "def try_hardburn_subtitles(final_video: Path, ass_file: Path, fonts_root: Path, out_mp4: Path):\n",
    "    if not has_subtitles_filter(): return False,\"ffmpeg 缺少 subtitles 濾鏡(libass)\"\n",
    "    candidates=[fonts_root/\"fonts\", fonts_root]\n",
    "    if os.name==\"nt\":\n",
    "        sys_fonts=Path(\"C:/Windows/Fonts\")\n",
    "        if sys_fonts.exists(): candidates.append(sys_fonts)\n",
    "    seen=set(); fonts_dirs=[]\n",
    "    for c in candidates:\n",
    "        key=c.resolve().as_posix().lower()\n",
    "        if key not in seen:\n",
    "            seen.add(key); fonts_dirs.append(c)\n",
    "    ass_posix=ass_file.as_posix(); ass_double=_double_escape_path(ass_file)\n",
    "    def variants(fd: Path):\n",
    "        fd_posix=fd.as_posix(); fd_double=_double_escape_path(fd)\n",
    "        return [\n",
    "            (\"double_escaped\",       f\"subtitles={ass_double}:fontsdir={fd_double}\"),\n",
    "            (\"double_escaped+force\", f\"subtitles={ass_double}:fontsdir={fd_double}:force_style='FontName={FONTNAME_FORCE_STYLE}'\"),\n",
    "            (\"plain\",                f\"subtitles={ass_posix}:fontsdir={fd_posix}\"),\n",
    "            (\"plain+force\",          f\"subtitles={ass_posix}:fontsdir={fd_posix}:force_style='FontName={FONTNAME_FORCE_STYLE}'\"),\n",
    "            (\"quoted\",               f\"subtitles='{ass_posix}':fontsdir='{fd_posix}'\"),\n",
    "        ]\n",
    "    last_tail=\"\"\n",
    "    for fd in fonts_dirs:\n",
    "        for label,vf in variants(fd):\n",
    "            proc=_run([\"ffmpeg\",\"-y\",\"-i\",str(final_video),\"-vf\",vf,\"-c:a\",\"copy\", str(out_mp4)], capture=True)\n",
    "            if proc.returncode==0 and out_mp4.exists() and out_mp4.stat().st_size>0:\n",
    "                return True,label\n",
    "            last_tail=(proc.stderr or \"\")[-400:]\n",
    "    return False,last_tail\n",
    "def fallback_soft_sub(final_video: Path, ass_file: Path, out_mkv: Path):\n",
    "    proc=_run([\"ffmpeg\",\"-y\",\"-i\",str(final_video),\"-i\",str(ass_file),\n",
    "               \"-map\",\"0\",\"-map\",\"1\",\"-c\",\"copy\", str(out_mkv)], capture=True)\n",
    "    if proc.returncode==0 and out_mkv.exists() and out_mkv.stat().st_size>0:\n",
    "        return True,\"soft-sub ok\"\n",
    "    return False,(proc.stderr or \"\")[-400:]\n",
    "\n",
    "# ---------------- 輸出流程 ----------------\n",
    "def quickcheck(plan):\n",
    "    lines=[]; scs=plan.get(\"scenes\",[]); lines.append(f\"[快速檢查] 場景數={len(scs)}\")\n",
    "    for sc in scs:\n",
    "        num=sc.get(\"number\"); af=sc.get(\"audio_file\"); im=sc.get(\"image_file\")\n",
    "        aok=af and (main_dir/af).exists(); iok=im and (main_dir/im).exists()\n",
    "        lines.append(f\"場景{num:03d} 音訊={'OK' if aok else '缺'} 圖片={'OK' if iok else '缺'}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def apply_profile_to_plan(plan: dict, settings: dict):\n",
    "    prof = settings.get(\"profile\") or {}\n",
    "    outp = prof.get(\"output\") or {}\n",
    "    w = int(outp.get(\"w\", 1920)); h=int(outp.get(\"h\",1080)); fps=int(outp.get(\"fps\",25))\n",
    "    plan[\"global\"][\"resolution\"]=[w,h]; plan[\"global\"][\"fps\"]=fps\n",
    "    return w,h,fps\n",
    "\n",
    "def render_from_plan(plan, log_output: W.Output, settings: dict):\n",
    "    with log_output: print(\"[輸出] 開始\")\n",
    "    # 用檔位覆蓋解析度/幀率\n",
    "    w,h,fps = apply_profile_to_plan(plan, settings)\n",
    "    events=build_subtitle_events(plan)\n",
    "    ass_path=write_ass(events, plan, main_dir/\"combined.ass\", settings=settings)\n",
    "    srt_path=write_srt(events, main_dir/\"combined.srt\")\n",
    "    with log_output: print(\"[輸出] 字幕檔產生完成\")\n",
    "\n",
    "    # 逐場景 - 嚴格確保每個場景的圖片/音訊時長匹配\n",
    "    clips=[]; total=0.0\n",
    "    total_scenes = len(plan.get(\"scenes\",[]))\n",
    "    for idx, sc in enumerate(plan.get(\"scenes\",[]), 1):\n",
    "        num=sc.get(\"number\")\n",
    "        with log_output: print(f\"[處理] 場景 {num:03d}/{total_scenes:03d} - 開始處理...\")\n",
    "        final_audio=process_scene_audio_return_final(sc, fallback_sec=DEFAULT_FALLBACK_DURATION)\n",
    "        dur=_ffprobe_duration(final_audio) or sc.get(\"duration_override\") or DEFAULT_FALLBACK_DURATION\n",
    "        total+=dur\n",
    "        clip=main_dir/f\"scene_{num:03d}_clip.mp4\"\n",
    "        with log_output: print(f\"[處理] 場景 {num:03d} - 音訊長度: {dur:.2f}秒, 生成片段中...\")\n",
    "        ok,label=make_scene_clip(sc.get(\"image_file\"), final_audio.name, dur, w, h, fps, clip)\n",
    "        if not ok: \n",
    "            with log_output: print(f\"[錯誤] 場景 {num:03d} - 片段生成失敗!\")\n",
    "            raise RuntimeError(f\"場景 {num} 片段失敗\")\n",
    "        with log_output: print(f\"[完成] 場景 {num:03d} - 成功生成 ({label}) ✓\")\n",
    "        clips.append(clip)\n",
    "\n",
    "    # 串接\n",
    "    concat=main_dir/\"concat.txt\"\n",
    "    with concat.open(\"w\",encoding=\"utf-8\") as f:\n",
    "        for c in clips: f.write(f\"file '{c.as_posix()}'\\n\")\n",
    "    base=main_dir/\"base_plain.mp4\"\n",
    "    res=_run([\"ffmpeg\",\"-y\",\"-f\",\"concat\",\"-safe\",\"0\",\"-i\",str(concat),\"-c\",\"copy\", str(base)], capture=True)\n",
    "    if not base.exists() or base.stat().st_size==0:\n",
    "        with log_output: print(\"[輸出] 串接copy失敗 → 改重編碼\")\n",
    "        _run([\"ffmpeg\",\"-y\",\"-f\",\"concat\",\"-safe\",\"0\",\"-i\",str(concat),\n",
    "              \"-c:v\",\"libx264\",\"-pix_fmt\",\"yuv420p\",\"-c:a\",\"aac\", str(base)], capture=True)\n",
    "        if not base.exists() or base.stat().st_size==0:\n",
    "            raise RuntimeError(\"串接失敗兩次\")\n",
    "\n",
    "    # 後製（含內建簡易/進階/檔案 Overlay）\n",
    "    post_out = main_dir/\"output_final.mp4\"\n",
    "    ok_pp, msg = postprocess_final_video(base, settings, post_out, base_w=w, base_h=h, base_fps=fps)\n",
    "    if not ok_pp:\n",
    "        with log_output: print(\"[後製] 失敗，訊息尾段：\", msg); shutil.copyfile(base, post_out)\n",
    "    else:\n",
    "        with log_output: print(\"[後製] 已套用：\", msg)\n",
    "\n",
    "    # 字幕硬燒 / 軟字幕\n",
    "    hard_sub=main_dir/\"output_final_subtitled.mp4\"\n",
    "    ok,msg=try_hardburn_subtitles(post_out, ass_path, main_dir, hard_sub)\n",
    "    if not ok:\n",
    "        with log_output: print(\"[字幕] 硬燒失敗 → 改封裝軟字幕\", msg)\n",
    "        soft_mkv=main_dir/\"output_final_subtitled.mkv\"\n",
    "        ok2,msg2=fallback_soft_sub(post_out, ass_path, soft_mkv)\n",
    "        with log_output: print(\"[字幕] 軟字幕：\", \"OK\" if ok2 else msg2)\n",
    "    else:\n",
    "        with log_output: print(\"[字幕] 硬燒 OK：\", msg)\n",
    "\n",
    "    # 輕量預覽\n",
    "    preview=main_dir/\"output_final_preview.mp4\"\n",
    "    _run([\"ffmpeg\",\"-y\",\"-i\",str(post_out),\n",
    "          \"-c:v\",\"libx264\",\"-crf\",\"30\",\"-preset\",\"veryfast\",\n",
    "          \"-c:a\",\"aac\",\"-b:a\",\"128k\", str(preview)])\n",
    "    with log_output: print(f\"[完成] 總長度：約 {total:.2f} 秒\")\n",
    "\n",
    "# ---------------- 步驟0：全域設定（含一鍵檔位） ----------------\n",
    "state = {\n",
    "    \"plan\": None,\n",
    "    \"images_list\": gather_images(),\n",
    "    \"audios_list\": gather_audios(),\n",
    "    \"overlay_list\": gather_overlay_candidates(),\n",
    "    \"settings\": load_settings()\n",
    "}\n",
    "\n",
    "# TTS 區塊\n",
    "tts_provider = W.Dropdown(options=[(\"OpenAI\",\"OPENAI\"),(\"Azure\",\"AZURE\"),(\"MiniMax\",\"MINIMAX\")],\n",
    "                          description=\"TTS 服務：\", value=state[\"settings\"][\"tts\"][\"provider\"])\n",
    "openai_model = W.Text(value=state[\"settings\"][\"tts\"][\"openai\"][\"model\"], description=\"模型(型號)：\", layout=W.Layout(width=\"240px\"))\n",
    "openai_voice = W.Text(value=state[\"settings\"][\"tts\"][\"openai\"][\"voice\"], description=\"聲音(音色)：\", layout=W.Layout(width=\"240px\"))\n",
    "openai_fmt   = W.Dropdown(options=[(\"MP3\",\"mp3\"),(\"WAV\",\"wav\")], value=state[\"settings\"][\"tts\"][\"openai\"][\"format\"], description=\"格式：\")\n",
    "azure_region= W.Text(value=state[\"settings\"][\"tts\"][\"azure\"].get(\"region\",\"\"), description=\"區域(region)：\", layout=W.Layout(width=\"220px\"))\n",
    "azure_voice = W.Text(value=state[\"settings\"][\"tts\"][\"azure\"][\"voice\"], description=\"聲音(音色)：\", layout=W.Layout(width=\"240px\"))\n",
    "azure_rate  = W.IntSlider(value=int(state[\"settings\"][\"tts\"][\"azure\"][\"rate_pct\"]), min=-50, max=50, step=1, description=\"語速(%)：\", continuous_update=False)\n",
    "azure_pitch = W.IntSlider(value=int(state[\"settings\"][\"tts\"][\"azure\"][\"pitch_pct\"]), min=-50, max=50, step=1, description=\"音高(%)：\", continuous_update=False)\n",
    "azure_fmt   = W.Dropdown(options=[(\"24kHz/48k單聲道MP3\",\"audio-24khz-48kbitrate-mono-mp3\"),\n",
    "                                  (\"48kHz/192k單聲道MP3\",\"audio-48khz-192kbitrate-mono-mp3\"),\n",
    "                                  (\"24kHz/16bit單聲道PCM\",\"riff-24khz-16bit-mono-pcm\")],\n",
    "                         value=state[\"settings\"][\"tts\"][\"azure\"][\"format\"], description=\"格式：\")\n",
    "minimax_model = W.Text(value=state[\"settings\"][\"tts\"][\"minimax\"][\"model\"], description=\"模型(型號)：\", layout=W.Layout(width=\"240px\"))\n",
    "minimax_voice = W.Text(value=state[\"settings\"][\"tts\"][\"minimax\"][\"voice_id\"], description=\"聲音ID：\", layout=W.Layout(width=\"240px\"))\n",
    "minimax_fmt   = W.Dropdown(options=[(\"MP3\",\"mp3\"),(\"WAV\",\"wav\")], value=state[\"settings\"][\"tts\"][\"minimax\"][\"format\"], description=\"格式：\")\n",
    "\n",
    "# 字幕\n",
    "subs_scale = W.IntSlider(value=int(state[\"settings\"][\"subs\"][\"scale_pct\"]), min=50, max=200, step=5, description=\"字幕大小(%)：\", continuous_update=False)\n",
    "\n",
    "# 後製基本\n",
    "denoise_enabled = W.Checkbox(value=state[\"settings\"][\"post\"][\"denoise\"][\"enabled\"], description=\"去雜訊(hqdn3d)\")\n",
    "denoise_preset  = W.Dropdown(options=[(\"低\",\"low\"),(\"中\",\"medium\"),(\"高\",\"high\")], value=state[\"settings\"][\"post\"][\"denoise\"][\"preset\"], description=\"強度：\")\n",
    "sharpen_enabled = W.Checkbox(value=state[\"settings\"][\"post\"][\"sharpen\"][\"enabled\"], description=\"銳利化(unsharp)\")\n",
    "sharpen_amount  = W.FloatSlider(value=float(state[\"settings\"][\"post\"][\"sharpen\"][\"amount\"]), min=0.0, max=2.0, step=0.05, description=\"強度：\", readout_format=\".2f\", continuous_update=False)\n",
    "color_enabled   = W.Checkbox(value=state[\"settings\"][\"post\"][\"color\"][\"enabled\"], description=\"顏色校正(eq)\")\n",
    "color_brightness= W.FloatSlider(value=float(state[\"settings\"][\"post\"][\"color\"][\"brightness\"]), min=-0.5, max=0.5, step=0.01, description=\"亮度：\", continuous_update=False)\n",
    "color_contrast  = W.FloatSlider(value=float(state[\"settings\"][\"post\"][\"color\"][\"contrast\"]), min=0.5, max=2.0, step=0.05, description=\"對比：\", continuous_update=False)\n",
    "color_saturation= W.FloatSlider(value=float(state[\"settings\"][\"post\"][\"color\"][\"saturation\"]), min=0.0, max=2.0, step=0.05, description=\"飽和：\", continuous_update=False)\n",
    "fps_enabled     = W.Checkbox(value=state[\"settings\"][\"post\"][\"fps_interp\"][\"enabled\"], description=\"補幀(變更幀率) minterpolate\")\n",
    "fps_target      = W.IntSlider(value=int(state[\"settings\"][\"post\"][\"fps_interp\"][\"fps\"]), min=24, max=120, step=1, description=\"目標幀率(FPS)：\", continuous_update=False)\n",
    "\n",
    "# 覆蓋層（兩層）\n",
    "def overlay_row(idx: int, ov: dict):\n",
    "    enabled = W.Checkbox(value=ov.get(\"enabled\", False), description=f\"覆蓋層 {idx}：啟用\")\n",
    "\n",
    "    # 矯正 mode 值（修正舊設定 \"builtin\"；以及任何不在 options 的值）\n",
    "    valid_modes = (\"file\", \"builtin_simple\", \"builtin_advanced\")\n",
    "    mode_val = str(ov.get(\"mode\", \"builtin_simple\") or \"builtin_simple\")\n",
    "    if mode_val == \"builtin\":\n",
    "        mode_val = \"builtin_simple\"\n",
    "    if mode_val not in valid_modes:\n",
    "        mode_val = \"builtin_simple\"\n",
    "    mode_dd = W.Dropdown(\n",
    "        options=[(\"檔案\",\"file\"),(\"內建(簡易)\",\"builtin_simple\"),(\"內建(進階)\",\"builtin_advanced\")],\n",
    "        value=mode_val,\n",
    "        description=\"模式：\"\n",
    "    )\n",
    "\n",
    "    opacity = W.FloatSlider(value=float(ov.get(\"opacity\",1.0)), min=0.0, max=1.0, step=0.05, description=\"透明度：\", continuous_update=False)\n",
    "    scale   = W.Checkbox(value=ov.get(\"scale_to_output\",True), description=\"跟隨輸出大小\")\n",
    "\n",
    "    # 檔案下拉：保證預設值存在於 options\n",
    "    files_options = state[\"overlay_list\"]\n",
    "    file_val = ov.get(\"file\",\"\") or \"\"\n",
    "    if file_val not in files_options:\n",
    "        file_val = \"\"\n",
    "    file_dd = W.Dropdown(options=files_options, value=file_val, description=\"檔案：\")\n",
    "\n",
    "    # 檔案類型：alpha/black/green\n",
    "    valid_types = (\"alpha\",\"black\",\"green\")\n",
    "    typ_val = ov.get(\"type\",\"alpha\")\n",
    "    if typ_val not in valid_types:\n",
    "        typ_val = \"alpha\"\n",
    "    typ_dd  = W.Dropdown(options=[(\"透明(含Alpha)\",\"alpha\"),(\"黑底\",\"black\"),(\"綠幕\",\"green\")], value=typ_val, description=\"檔案類型：\")\n",
    "    # 黑底混合\n",
    "    valid_black_modes = (\"screen\",\"addition\")\n",
    "    black_mode_val = (ov.get(\"black\") or {}).get(\"mode\",\"screen\")\n",
    "    if black_mode_val not in valid_black_modes:\n",
    "        black_mode_val = \"screen\"\n",
    "    black_mode = W.Dropdown(options=[(\"變亮(Screen)\",\"screen\"),(\"相加(Addition)\",\"addition\")], value=black_mode_val, description=\"黑底混合：\")\n",
    "\n",
    "    # 綠幕去背\n",
    "    green_cfg = ov.get(\"greenscreen\") or {}\n",
    "    green_color= W.Text(value=green_cfg.get(\"color\",\"0x00FF00\"), description=\"去背顏色：\")\n",
    "    green_sim  = W.FloatSlider(value=float(green_cfg.get(\"similarity\",0.20)), min=0.0, max=1.0, step=0.01, description=\"相似度：\", continuous_update=False)\n",
    "    green_blend= W.FloatSlider(value=float(green_cfg.get(\"blend\",0.10)), min=0.0, max=1.0, step=0.01, description=\"融合：\", continuous_update=False)\n",
    "    file_box = W.VBox([W.HBox([file_dd, typ_dd, black_mode]), W.HBox([green_color, green_sim, green_blend])])\n",
    "\n",
    "    # 內建(簡易)\n",
    "    simp = ov.get(\"simple\") or {}\n",
    "    valid_kinds = (\"snow\",\"rain\",\"leaves\")\n",
    "    simple_kind_val = simp.get(\"kind\",\"snow\")\n",
    "    if simple_kind_val not in valid_kinds:\n",
    "        simple_kind_val = \"snow\"\n",
    "    simple_kind = W.Dropdown(options=[(\"雪\",\"snow\"),(\"雨\",\"rain\"),(\"樹葉\",\"leaves\")], value=simple_kind_val, description=\"類型：\")\n",
    "    simple_dens = W.IntSlider(value=int(simp.get(\"density\",30)), min=1, max=200, step=1, description=\"密度：\", continuous_update=False)\n",
    "    simple_size = W.IntSlider(value=int(simp.get(\"size\",48)), min=8, max=200, step=1, description=\"大小(px)：\", continuous_update=False)\n",
    "    simple_speed= W.IntSlider(value=int(simp.get(\"speed\",120)), min=10, max=600, step=5, description=\"速度：\", continuous_update=False)\n",
    "    simple_color= W.Text(value=simp.get(\"color\",\"white\"), description=\"顏色：\")\n",
    "    simple_box = W.HBox([simple_kind, simple_dens, simple_size, simple_speed, simple_color])\n",
    "\n",
    "    # 內建(進階)\n",
    "    adv = ov.get(\"advanced\") or {}\n",
    "    adv_kind_val = adv.get(\"kind\",\"snow\")\n",
    "    if adv_kind_val not in valid_kinds:\n",
    "        adv_kind_val = \"snow\"\n",
    "    adv_kind = W.Dropdown(options=[(\"雪\",\"snow\"),(\"雨\",\"rain\"),(\"樹葉\",\"leaves\")], value=adv_kind_val, description=\"類型：\")\n",
    "    adv_density = W.IntSlider(value=int(adv.get(\"density\",60)), min=1, max=200, step=1, description=\"數量：\", continuous_update=False)\n",
    "    adv_size_min= W.IntSlider(value=int(adv.get(\"size_min\",20)), min=6, max=200, step=1, description=\"最小大小：\", continuous_update=False)\n",
    "    adv_size_max= W.IntSlider(value=int(adv.get(\"size_max\",64)), min=8, max=240, step=1, description=\"最大大小：\", continuous_update=False)\n",
    "    adv_spd_min = W.IntSlider(value=int(adv.get(\"speed_min\",60)), min=10, max=600, step=5, description=\"最慢速度：\", continuous_update=False)\n",
    "    adv_spd_max = W.IntSlider(value=int(adv.get(\"speed_max\",180)), min=10, max=800, step=5, description=\"最快速度：\", continuous_update=False)\n",
    "    adv_drift   = W.IntSlider(value=int(adv.get(\"drift\",60)), min=0, max=200, step=1, description=\"左右飄幅：\", continuous_update=False)\n",
    "    adv_turb    = W.IntSlider(value=int(adv.get(\"turbulence\",25)), min=0, max=200, step=1, description=\"亂流：\", continuous_update=False)\n",
    "    adv_rot_min = W.IntSlider(value=int(adv.get(\"rotation_min\",-90)), min=-360, max=360, step=5, description=\"最小旋轉：\", continuous_update=False)\n",
    "    adv_rot_max = W.IntSlider(value=int(adv.get(\"rotation_max\", 90)), min=-360, max=360, step=5, description=\"最大旋轉：\", continuous_update=False)\n",
    "    adv_loop    = W.IntSlider(value=int(adv.get(\"loop_sec\",8)), min=2, max=20, step=1, description=\"循環秒數：\", continuous_update=False)\n",
    "    adv_seed    = W.IntText(value=int(adv.get(\"seed\",1337)), description=\"隨機種子：\")\n",
    "\n",
    "    # 自訂貼圖下拉：確保值存在於 options\n",
    "    adv_tex_options = [\"\"] + [p.name for p in main_dir.glob(\"*.png\")]\n",
    "    adv_tex_val = Path(adv.get(\"texture_file\",\"\")).name if adv.get(\"texture_file\") else \"\"\n",
    "    if adv_tex_val not in adv_tex_options:\n",
    "        adv_tex_val = \"\"\n",
    "    adv_tex     = W.Dropdown(options=adv_tex_options, value=adv_tex_val, description=\"自訂貼圖：\")\n",
    "\n",
    "    adv_box1    = W.HBox([adv_kind, adv_density, adv_size_min, adv_size_max, adv_spd_min, adv_spd_max])\n",
    "    adv_box2    = W.HBox([adv_drift, adv_turb, adv_rot_min, adv_rot_max, adv_loop, adv_seed, adv_tex])\n",
    "\n",
    "    builtin_simple_box  = W.VBox([simple_box])\n",
    "    builtin_advanced_box= W.VBox([adv_box1, adv_box2])\n",
    "\n",
    "    def on_mode_change(change):\n",
    "        m = change[\"new\"]\n",
    "        file_box.layout.display    = None if m==\"file\" else \"none\"\n",
    "        builtin_simple_box.layout.display   = None if m==\"builtin_simple\" else \"none\"\n",
    "        builtin_advanced_box.layout.display = None if m==\"builtin_advanced\" else \"none\"\n",
    "    mode_dd.observe(on_mode_change, names=\"value\")\n",
    "    on_mode_change({\"new\": mode_dd.value})\n",
    "\n",
    "    row = W.VBox([\n",
    "        W.HBox([enabled, mode_dd, opacity, scale]),\n",
    "        file_box,\n",
    "        builtin_simple_box,\n",
    "        builtin_advanced_box\n",
    "    ], layout=W.Layout(border=\"1px solid #ddd\", padding=\"6px\"))\n",
    "    return {\n",
    "        \"widget\": row,\n",
    "        \"enabled\": enabled,\n",
    "        \"mode_dd\": mode_dd,\n",
    "        \"opacity\": opacity,\n",
    "        \"scale\": scale,\n",
    "        # file\n",
    "        \"file_dd\": file_dd, \"typ_dd\": typ_dd, \"black_mode\": black_mode,\n",
    "        \"green_color\": green_color, \"green_sim\": green_sim, \"green_blend\": green_blend,\n",
    "        # simple\n",
    "        \"simple_kind\": simple_kind, \"simple_dens\": simple_dens, \"simple_size\": simple_size, \"simple_speed\": simple_speed, \"simple_color\": simple_color,\n",
    "        # advanced\n",
    "        \"adv_kind\": adv_kind, \"adv_density\": adv_density, \"adv_size_min\": adv_size_min, \"adv_size_max\": adv_size_max,\n",
    "        \"adv_spd_min\": adv_spd_min, \"adv_spd_max\": adv_spd_max, \"adv_drift\": adv_drift, \"adv_turb\": adv_turb,\n",
    "        \"adv_rot_min\": adv_rot_min, \"adv_rot_max\": adv_rot_max, \"adv_loop\": adv_loop, \"adv_seed\": adv_seed, \"adv_tex\": adv_tex\n",
    "    }\n",
    "\n",
    "ov_widgets = []\n",
    "post_ovs = state[\"settings\"][\"post\"][\"overlays\"]\n",
    "for i in range(2):\n",
    "    ov_widgets.append(overlay_row(i+1, post_ovs[i] if i < len(post_ovs) else {}))\n",
    "\n",
    "# 設定按鈕/狀態\n",
    "settings_status = W.Output(layout=W.Layout(border=\"1px solid #ccc\", max_height=\"160px\", overflow=\"auto\"))\n",
    "btn_settings_save = W.Button(description=\"儲存設定\", button_style=\"success\", icon=\"save\")\n",
    "btn_settings_reload = W.Button(description=\"重新讀取\", icon=\"refresh\")\n",
    "btn_settings_reset = W.Button(description=\"回預設\", icon=\"undo\")\n",
    "\n",
    "# 一鍵檔位：省資源/均衡/頂規\n",
    "btn_prof_eco = W.Button(description=\"一鍵：省資源\", icon=\"leaf\", button_style=\"\")\n",
    "btn_prof_bal = W.Button(description=\"一鍵：均衡\", icon=\"adjust\", button_style=\"info\")\n",
    "btn_prof_ultra=W.Button(description=\"一鍵：頂規\", icon=\"star\", button_style=\"warning\")\n",
    "lbl_prof = W.Label(value=f\"目前檔位：{(state['settings'].get('profile') or {}).get('name','eco')}\")\n",
    "\n",
    "def apply_profile_to_ui(name: str):\n",
    "    # 讀現有設定做基底\n",
    "    s = load_settings()\n",
    "    s[\"profile\"][\"name\"] = name\n",
    "    if name==\"eco\":\n",
    "        s[\"profile\"][\"output\"] = {\"w\":1280,\"h\":720,\"fps\":25}\n",
    "        s[\"profile\"][\"adv_half_res\"] = True\n",
    "        s[\"profile\"][\"vp9\"] = {\"crf\":32,\"cpu_used\":8,\"tile_columns\":2,\"row_mt\":1,\"auto_alt_ref\":0}\n",
    "        s[\"post\"][\"denoise\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"sharpen\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"color\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"fps_interp\"][\"enabled\"]=False\n",
    "        if s[\"post\"][\"overlays\"]:\n",
    "            s[\"post\"][\"overlays\"][0].update({\n",
    "                \"enabled\": True, \"mode\":\"builtin_simple\", \"opacity\":1.0,\n",
    "                \"simple\":{\"kind\":\"snow\",\"density\":35,\"size\":36,\"speed\":130,\"color\":\"white\"},\n",
    "            })\n",
    "        if len(s[\"post\"][\"overlays\"])>1:\n",
    "            s[\"post\"][\"overlays\"][1][\"enabled\"]=False\n",
    "    elif name==\"balanced\":\n",
    "        s[\"profile\"][\"output\"] = {\"w\":1920,\"h\":1080,\"fps\":25}\n",
    "        s[\"profile\"][\"adv_half_res\"] = True\n",
    "        s[\"profile\"][\"vp9\"] = {\"crf\":30,\"cpu_used\":6,\"tile_columns\":2,\"row_mt\":1,\"auto_alt_ref\":0}\n",
    "        s[\"post\"][\"denoise\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"sharpen\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"color\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"fps_interp\"][\"enabled\"]=False\n",
    "        if s[\"post\"][\"overlays\"]:\n",
    "            s[\"post\"][\"overlays\"][0].update({\n",
    "                \"enabled\": True, \"mode\":\"builtin_advanced\", \"opacity\":1.0,\n",
    "                \"advanced\":{\"kind\":\"snow\",\"density\":50,\"size_min\":24,\"size_max\":64,\n",
    "                            \"speed_min\":60,\"speed_max\":160,\"drift\":60,\"turbulence\":25,\n",
    "                            \"rotation_min\":-60,\"rotation_max\":60,\"layers\":{\"near\":0.4,\"mid\":0.35,\"far\":0.25},\n",
    "                            \"loop_sec\":8,\"seed\":1337,\"texture_file\":\"\"}\n",
    "            })\n",
    "        if len(s[\"post\"][\"overlays\"])>1:\n",
    "            s[\"post\"][\"overlays\"][1].update({\"enabled\": False})\n",
    "    else:  # ultra\n",
    "        s[\"profile\"][\"output\"] = {\"w\":1920,\"h\":1080,\"fps\":25}  # 想要 4K 可改 \"w\":3840,\"h\":2160\n",
    "        s[\"profile\"][\"adv_half_res\"] = False\n",
    "        s[\"profile\"][\"vp9\"] = {\"crf\":28,\"cpu_used\":4,\"tile_columns\":2,\"row_mt\":1,\"auto_alt_ref\":0}\n",
    "        s[\"post\"][\"denoise\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"sharpen\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"color\"][\"enabled\"]=False\n",
    "        s[\"post\"][\"fps_interp\"][\"enabled\"]=False\n",
    "        if s[\"post\"][\"overlays\"]:\n",
    "            s[\"post\"][\"overlays\"][0].update({\n",
    "                \"enabled\": True, \"mode\":\"builtin_advanced\", \"opacity\":1.0,\n",
    "                \"advanced\":{\"kind\":\"snow\",\"density\":90,\"size_min\":24,\"size_max\":80,\n",
    "                            \"speed_min\":60,\"speed_max\":200,\"drift\":90,\"turbulence\":35,\n",
    "                            \"rotation_min\":-120,\"rotation_max\":120,\"layers\":{\"near\":0.4,\"mid\":0.35,\"far\":0.25},\n",
    "                            \"loop_sec\":12,\"seed\":2024,\"texture_file\":\"\"}\n",
    "            })\n",
    "        if len(s[\"post\"][\"overlays\"])>1:\n",
    "            s[\"post\"][\"overlays\"][1].update({\n",
    "                \"enabled\": True, \"mode\":\"builtin_advanced\", \"opacity\":0.9,\n",
    "                \"advanced\":{\"kind\":\"leaves\",\"density\":36,\"size_min\":24,\"size_max\":72,\n",
    "                            \"speed_min\":80,\"speed_max\":160,\"drift\":90,\"turbulence\":35,\n",
    "                            \"rotation_min\":-120,\"rotation_max\":120,\"layers\":{\"near\":0.5,\"mid\":0.3,\"far\":0.2},\n",
    "                            \"loop_sec\":8,\"seed\":2025,\"texture_file\":\"\"}\n",
    "            })\n",
    "    # 關鍵：先存檔，再 reload 面板，避免被舊檔案覆蓋\n",
    "    save_settings(s)\n",
    "    state[\"settings\"]=s\n",
    "    on_settings_reload()  # 這次會讀到剛存的值\n",
    "    lbl_prof.value=f\"目前檔位：{name}\"\n",
    "    with settings_status:\n",
    "        clear_output()\n",
    "        print(f\"[檔位] 已套用「{name}」並寫入 settings.json（面板已同步）。\")\n",
    "        \n",
    "btn_prof_eco.on_click(lambda _: apply_profile_to_ui(\"eco\"))\n",
    "btn_prof_bal.on_click(lambda _: apply_profile_to_ui(\"balanced\"))\n",
    "btn_prof_ultra.on_click(lambda _: apply_profile_to_ui(\"ultra\"))\n",
    "\n",
    "def collect_settings_from_ui():\n",
    "    s = load_settings()\n",
    "    # TTS\n",
    "    s[\"tts\"][\"provider\"] = tts_provider.value\n",
    "    s[\"tts\"][\"openai\"][\"model\"] = openai_model.value.strip() or \"tts-1\"\n",
    "    s[\"tts\"][\"openai\"][\"voice\"] = openai_voice.value.strip() or \"alloy\"\n",
    "    s[\"tts\"][\"openai\"][\"format\"]= openai_fmt.value\n",
    "    s[\"tts\"][\"azure\"][\"region\"] = azure_region.value.strip()\n",
    "    s[\"tts\"][\"azure\"][\"voice\"]  = azure_voice.value.strip() or \"zh-TW-HsiaoChenNeural\"\n",
    "    s[\"tts\"][\"azure\"][\"rate_pct\"]= int(azure_rate.value)\n",
    "    s[\"tts\"][\"azure\"][\"pitch_pct\"]= int(azure_pitch.value)\n",
    "    s[\"tts\"][\"azure\"][\"format\"] = azure_fmt.value\n",
    "    s[\"tts\"][\"minimax\"][\"model\"]= minimax_model.value.strip() or \"speech-01\"\n",
    "    s[\"tts\"][\"minimax\"][\"voice_id\"]= minimax_voice.value.strip() or \"female-1\"\n",
    "    s[\"tts\"][\"minimax\"][\"format\"]= minimax_fmt.value\n",
    "    # Subs\n",
    "    s[\"subs\"][\"scale_pct\"]= int(subs_scale.value)\n",
    "    # Post basics\n",
    "    s[\"post\"][\"denoise\"][\"enabled\"] = bool(denoise_enabled.value)\n",
    "    s[\"post\"][\"denoise\"][\"preset\"]  = denoise_preset.value\n",
    "    s[\"post\"][\"sharpen\"][\"enabled\"] = bool(sharpen_enabled.value)\n",
    "    s[\"post\"][\"sharpen\"][\"amount\"]  = float(sharpen_amount.value)\n",
    "    s[\"post\"][\"color\"][\"enabled\"]   = bool(color_enabled.value)\n",
    "    s[\"post\"][\"color\"][\"brightness\"]= float(color_brightness.value)\n",
    "    s[\"post\"][\"color\"][\"contrast\"]  = float(color_contrast.value)\n",
    "    s[\"post\"][\"color\"][\"saturation\"]= float(color_saturation.value)\n",
    "    s[\"post\"][\"fps_interp\"][\"enabled\"]= bool(fps_enabled.value)\n",
    "    s[\"post\"][\"fps_interp\"][\"fps\"]    = int(fps_target.value)\n",
    "    # Overlays\n",
    "    ovs=[]\n",
    "    for ow in ov_widgets:\n",
    "        adv_tex_name = ow[\"adv_tex\"].value or \"\"\n",
    "        adv_tex_path = (main_dir/adv_tex_name).as_posix() if adv_tex_name else \"\"\n",
    "        ov={\n",
    "            \"enabled\": bool(ow[\"enabled\"].value),\n",
    "            \"mode\": ow[\"mode_dd\"].value,\n",
    "            \"file\": ow[\"file_dd\"].value or \"\",\n",
    "            \"type\": ow[\"typ_dd\"].value,\n",
    "            \"opacity\": float(ow[\"opacity\"].value),\n",
    "            \"scale_to_output\": bool(ow[\"scale\"].value),\n",
    "            \"black\": {\"mode\": ow[\"black_mode\"].value},\n",
    "            \"greenscreen\": {\n",
    "                \"color\": ow[\"green_color\"].value or \"0x00FF00\",\n",
    "                \"similarity\": float(ow[\"green_sim\"].value),\n",
    "                \"blend\": float(ow[\"green_blend\"].value)\n",
    "            },\n",
    "            \"simple\": {\n",
    "                \"kind\": ow[\"simple_kind\"].value,\n",
    "                \"density\": int(ow[\"simple_dens\"].value),\n",
    "                \"size\": int(ow[\"simple_size\"].value),\n",
    "                \"speed\": int(ow[\"simple_speed\"].value),\n",
    "                \"color\": ow[\"simple_color\"].value or \"white\"\n",
    "            },\n",
    "            \"advanced\": {\n",
    "                \"kind\": ow[\"adv_kind\"].value,\n",
    "                \"density\": int(ow[\"adv_density\"].value),\n",
    "                \"size_min\": int(ow[\"adv_size_min\"].value),\n",
    "                \"size_max\": int(ow[\"adv_size_max\"].value),\n",
    "                \"speed_min\": int(ow[\"adv_spd_min\"].value),\n",
    "                \"speed_max\": int(ow[\"adv_spd_max\"].value),\n",
    "                \"drift\": float(ow[\"adv_drift\"].value),\n",
    "                \"turbulence\": float(ow[\"adv_turb\"].value),\n",
    "                \"rotation_min\": float(ow[\"adv_rot_min\"].value),\n",
    "                \"rotation_max\": float(ow[\"adv_rot_max\"].value),\n",
    "                \"layers\": {\"near\":0.4,\"mid\":0.35,\"far\":0.25},  # 固定比例（需要UI再開）\n",
    "                \"loop_sec\": int(ow[\"adv_loop\"].value),\n",
    "                \"seed\": int(ow[\"adv_seed\"].value),\n",
    "                \"texture_file\": adv_tex_path\n",
    "            }\n",
    "        }\n",
    "        ovs.append(ov)\n",
    "    s[\"post\"][\"overlays\"]= ovs\n",
    "    # 檔位名維持\n",
    "    if \"profile\" not in s: s[\"profile\"] = default_settings()[\"profile\"]\n",
    "    return s\n",
    "\n",
    "def on_settings_save(_b=None):\n",
    "    s = collect_settings_from_ui()\n",
    "    save_settings(s); state[\"settings\"] = s\n",
    "    with settings_status:\n",
    "        clear_output()\n",
    "        print(\"[設定] 已儲存到 settings.json\")\n",
    "        print(\"目前檔位：\", (s.get(\"profile\") or {}).get(\"name\",\"eco\"))\n",
    "        print(\"ffmpeg 可用:\", bool(shutil.which(\"ffmpeg\")))\n",
    "\n",
    "def on_settings_reload(_b=None):\n",
    "    s = load_settings(); state[\"settings\"] = s\n",
    "    tts_provider.value = s[\"tts\"][\"provider\"]\n",
    "    openai_model.value = s[\"tts\"][\"openai\"][\"model\"]; openai_voice.value = s[\"tts\"][\"openai\"][\"voice\"]; openai_fmt.value=s[\"tts\"][\"openai\"][\"format\"]\n",
    "    azure_region.value = s[\"tts\"][\"azure\"].get(\"region\",\"\"); azure_voice.value=s[\"tts\"][\"azure\"][\"voice\"]; azure_rate.value=int(s[\"tts\"][\"azure\"][\"rate_pct\"]); azure_pitch.value=int(s[\"tts\"][\"azure\"][\"pitch_pct\"]); azure_fmt.value=s[\"tts\"][\"azure\"][\"format\"]\n",
    "    minimax_model.value=s[\"tts\"][\"minimax\"][\"model\"]; minimax_voice.value=s[\"tts\"][\"minimax\"][\"voice_id\"]; minimax_fmt.value=s[\"tts\"][\"minimax\"][\"format\"]\n",
    "    subs_scale.value=int(s[\"subs\"][\"scale_pct\"])\n",
    "    denoise_enabled.value=s[\"post\"][\"denoise\"][\"enabled\"]; denoise_preset.value=s[\"post\"][\"denoise\"][\"preset\"]\n",
    "    sharpen_enabled.value=s[\"post\"][\"sharpen\"][\"enabled\"]; sharpen_amount.value=float(s[\"post\"][\"sharpen\"][\"amount\"])\n",
    "    color_enabled.value=s[\"post\"][\"color\"][\"enabled\"]; color_brightness.value=float(s[\"post\"][\"color\"][\"brightness\"]); color_contrast.value=float(s[\"post\"][\"color\"][\"contrast\"]); color_saturation.value=float(s[\"post\"][\"color\"][\"saturation\"])\n",
    "    fps_enabled.value=s[\"post\"][\"fps_interp\"][\"enabled\"]; fps_target.value=int(s[\"post\"][\"fps_interp\"][\"fps\"])\n",
    "    # overlays\n",
    "    state[\"overlay_list\"] = gather_overlay_candidates()\n",
    "    for i,ow in enumerate(ov_widgets):\n",
    "        ov = s[\"post\"][\"overlays\"][i] if i < len(s[\"post\"][\"overlays\"]) else {}\n",
    "        ow[\"enabled\"].value = ov.get(\"enabled\",False)\n",
    "        ow[\"mode_dd\"].value = ov.get(\"mode\",\"builtin_simple\")\n",
    "        ow[\"file_dd\"].options = state[\"overlay_list\"]; ow[\"file_dd\"].value = ov.get(\"file\",\"\") if ov.get(\"file\",\"\") in ow[\"file_dd\"].options else \"\"\n",
    "        ow[\"typ_dd\"].value  = ov.get(\"type\",\"alpha\")\n",
    "        ow[\"black_mode\"].value = (ov.get(\"black\") or {}).get(\"mode\",\"screen\")\n",
    "        ow[\"green_color\"].value= (ov.get(\"greenscreen\") or {}).get(\"color\",\"0x00FF00\")\n",
    "        ow[\"green_sim\"].value  = float((ov.get(\"greenscreen\") or {}).get(\"similarity\",0.20))\n",
    "        ow[\"green_blend\"].value= float((ov.get(\"greenscreen\") or {}).get(\"blend\",0.10))\n",
    "        simp = ov.get(\"simple\") or {}\n",
    "        ow[\"simple_kind\"].value = simp.get(\"kind\",\"snow\")\n",
    "        ow[\"simple_dens\"].value = int(simp.get(\"density\",30))\n",
    "        ow[\"simple_size\"].value = int(simp.get(\"size\",48))\n",
    "        ow[\"simple_speed\"].value= int(simp.get(\"speed\",120))\n",
    "        ow[\"simple_color\"].value= simp.get(\"color\",\"white\")\n",
    "        adv = ov.get(\"advanced\") or {}\n",
    "        ow[\"adv_kind\"].value = adv.get(\"kind\",\"snow\")\n",
    "        ow[\"adv_density\"].value = int(adv.get(\"density\",60))\n",
    "        ow[\"adv_size_min\"].value = int(adv.get(\"size_min\",20))\n",
    "        ow[\"adv_size_max\"].value = int(adv.get(\"size_max\",64))\n",
    "        ow[\"adv_spd_min\"].value  = int(adv.get(\"speed_min\",60))\n",
    "        ow[\"adv_spd_max\"].value  = int(adv.get(\"speed_max\",180))\n",
    "        ow[\"adv_drift\"].value    = int(adv.get(\"drift\",60))\n",
    "        ow[\"adv_turb\"].value     = int(adv.get(\"turbulence\",25))\n",
    "        ow[\"adv_rot_min\"].value  = int(adv.get(\"rotation_min\",-90))\n",
    "        ow[\"adv_rot_max\"].value  = int(adv.get(\"rotation_max\", 90))\n",
    "        ow[\"adv_loop\"].value     = int(adv.get(\"loop_sec\",8))\n",
    "        ow[\"adv_seed\"].value     = int(adv.get(\"seed\",1337))\n",
    "        ow[\"adv_tex\"].options = [\"\"] + [p.name for p in main_dir.glob(\"*.png\")]\n",
    "        cur_tex = Path(adv.get(\"texture_file\",\"\")).name if adv.get(\"texture_file\") else \"\"\n",
    "        ow[\"adv_tex\"].value = cur_tex if cur_tex in ow[\"adv_tex\"].options else \"\"\n",
    "    lbl_prof.value=f\"目前檔位：{(s.get('profile') or {}).get('name','eco')}\"\n",
    "    with settings_status:\n",
    "        clear_output(); print(\"[設定] 已重新讀取 settings.json\")\n",
    "\n",
    "def on_settings_reset(_b=None):\n",
    "    s = default_settings(); save_settings(s); state[\"settings\"]=s; on_settings_reload()\n",
    "\n",
    "btn_settings_save.on_click(on_settings_save)\n",
    "btn_settings_reload.on_click(on_settings_reload)\n",
    "btn_settings_reset.on_click(on_settings_reset)\n",
    "\n",
    "# UI 群組\n",
    "openai_box = W.HBox([openai_model, openai_voice, openai_fmt])\n",
    "azure_box  = W.HBox([azure_region, azure_voice, azure_fmt])\n",
    "azure_box2 = W.HBox([azure_rate, azure_pitch])\n",
    "minimax_box= W.HBox([minimax_model, minimax_voice, minimax_fmt])\n",
    "subs_box = W.HBox([subs_scale])\n",
    "post_row1 = W.HBox([denoise_enabled, denoise_preset, sharpen_enabled, sharpen_amount])\n",
    "post_row2 = W.HBox([color_enabled, color_brightness, color_contrast, color_saturation])\n",
    "post_row3 = W.HBox([fps_enabled, fps_target])\n",
    "profile_row = W.HBox([btn_prof_eco, btn_prof_bal, btn_prof_ultra, lbl_prof])\n",
    "\n",
    "settings_ui = W.VBox([\n",
    "    W.HTML(\"<b>步驟0：全域設定（前製 TTS / 後製效果 / 字幕大小 / 一鍵檔位）</b>\"),\n",
    "    W.HTML(\"<u>一鍵檔位</u>（點選後面板會更新，記得按「儲存設定」）\"),\n",
    "    profile_row,\n",
    "    W.HTML(\"<u>TTS 語音設定</u>\"),\n",
    "    tts_provider, W.HTML(\"OpenAI\"), openai_box, W.HTML(\"Azure\"), azure_box, azure_box2, W.HTML(\"MiniMax（骨架）\"), minimax_box,\n",
    "    W.HTML(\"<u>字幕大小（百分比，ASS Style ScaleX/ScaleY）</u>\"), subs_box,\n",
    "    W.HTML(\"<u>後製效果（ffmpeg 濾鏡）</u>\"), post_row1, post_row2, post_row3,\n",
    "    W.HTML(\"<i>飄落特效 / 覆蓋層（最多 2 層；模式可選 檔案 / 內建(簡易) / 內建(進階)）</i>\"),\n",
    "    ov_widgets[0][\"widget\"], ov_widgets[1][\"widget\"],\n",
    "    W.HBox([btn_settings_save, btn_settings_reload, btn_settings_reset]),\n",
    "    settings_status,\n",
    "    W.HTML(\"<hr>\")\n",
    "])\n",
    "display(settings_ui)\n",
    "\n",
    "# ---------------- 步驟1：分鏡編輯器 ----------------\n",
    "status_out=W.Output(layout=W.Layout(border=\"1px solid #ccc\", max_height=\"200px\", overflow=\"auto\"))\n",
    "log_out   =W.Output(layout=W.Layout(border=\"1px solid #ccc\", max_height=\"260px\", overflow=\"auto\"))\n",
    "\n",
    "ta_text   =W.Textarea(value=\"\", placeholder=\"貼上腳本：每行=一個分鏡(Scene)\", layout=W.Layout(width=\"100%\", height=\"120px\"))\n",
    "btn_import=W.Button(description=\"載入文字(重建)\", button_style=\"info\", icon=\"upload\")\n",
    "btn_qc    =W.Button(description=\"快速檢查\", icon=\"search\")\n",
    "btn_save  =W.Button(description=\"儲存規劃檔\", button_style=\"success\", icon=\"save\")\n",
    "btn_pre   =W.Button(description=\"檔案檢查\", icon=\"check\")\n",
    "btn_render=W.Button(description=\"輸出影片\", button_style=\"primary\", icon=\"film\")\n",
    "btn_refresh_img=W.Button(description=\"重整圖片清單\", icon=\"refresh\")\n",
    "btn_refresh_aud=W.Button(description=\"重整音訊清單\", icon=\"refresh\")\n",
    "\n",
    "scenes_box=W.VBox([])\n",
    "\n",
    "def rebuild_scenes_ui():\n",
    "    rows=[]; plan=state[\"plan\"]\n",
    "    if not plan: scenes_box.children=[]; return\n",
    "    imgs=gather_images(); auds=gather_audios()\n",
    "    for sc in plan.get(\"scenes\",[]):\n",
    "        num=sc[\"number\"]\n",
    "        preview=W.Output(layout=W.Layout(border=\"1px solid #ccc\", width=\"200px\", height=\"160px\"))\n",
    "        with preview:\n",
    "            imgf=sc.get(\"image_file\")\n",
    "            if imgf and (main_dir/imgf).exists():\n",
    "                from IPython.display import Image as IPyImage; display(IPyImage(filename=str(main_dir/imgf)))\n",
    "            else:\n",
    "                print(\"(尚無圖片)\")\n",
    "        sub_area=W.Textarea(value=sc.get(\"subtitle_text\") or sc.get(\"raw_text\") or \"\", placeholder=f\"字幕 (場景{num})\", layout=W.Layout(width=\"100%\", height=\"70px\"))\n",
    "        audio_dd=W.Dropdown(options=auds, value=sc.get(\"audio_file\") or \"\", description=f\"音訊 {num}：\", layout=W.Layout(width=\"280px\"))\n",
    "        tts_btn=W.Button(description=\"產生語音(TTS)\", icon=\"microphone\", layout=W.Layout(width=\"130px\"))\n",
    "        audio_play=W.Output(layout=W.Layout(border=\"1px solid #eee\", width=\"100%\", height=\"70px\"))\n",
    "        def refresh_audio_player():\n",
    "            with audio_play:\n",
    "                clear_output()\n",
    "                af=sc.get(\"audio_file\")\n",
    "                if af and (main_dir/af).exists():\n",
    "                    from IPython.display import Audio as IPyAudio; display(IPyAudio(filename=str(main_dir/af), autoplay=False))\n",
    "                else:\n",
    "                    print(\"(尚無音訊)\")\n",
    "        prompt_area=W.Textarea(value=sc.get(\"ai_prompt\") or \"\", placeholder=f\"圖片提示(場景{num})\", layout=W.Layout(width=\"100%\", height=\"70px\"))\n",
    "        image_dd=W.Dropdown(options=imgs, value=sc.get(\"image_file\") or \"\", description=f\"圖片 {num}：\", layout=W.Layout(width=\"280px\"))\n",
    "        img_btn=W.Button(description=\"AI 產生圖片\", icon=\"image\", layout=W.Layout(width=\"120px\"))\n",
    "\n",
    "        def on_sub_change(change, sc=sc): sc[\"subtitle_text\"]=change[\"new\"]; sc[\"raw_text\"]=change[\"new\"]\n",
    "        sub_area.observe(on_sub_change, names=\"value\")\n",
    "        def on_prompt_change(change, sc=sc): sc[\"ai_prompt\"]=change[\"new\"]\n",
    "        prompt_area.observe(on_prompt_change, names=\"value\")\n",
    "        def on_audio_dd(change, sc=sc): sc[\"audio_file\"]=change[\"new\"] or None; refresh_audio_player()\n",
    "        audio_dd.observe(on_audio_dd, names=\"value\")\n",
    "        def on_image_dd(change, sc=sc, preview=preview):\n",
    "            sc[\"image_file\"]=change[\"new\"] or None\n",
    "            with preview:\n",
    "                clear_output()\n",
    "                imgf=sc.get(\"image_file\")\n",
    "                if imgf and (main_dir/imgf).exists():\n",
    "                    from IPython.display import Image as IPyImage; display(IPyImage(filename=str(main_dir/imgf)))\n",
    "                else:\n",
    "                    print(\"(尚無圖片)\")\n",
    "        image_dd.observe(on_image_dd, names=\"value\")\n",
    "\n",
    "        def on_tts_click(_b, sc=sc, audio_dd=audio_dd):\n",
    "            text=sc.get(\"subtitle_text\") or sc.get(\"raw_text\") or \"\"\n",
    "            outstem=main_dir/f\"scene_{sc.get('number'):03d}_tts\"\n",
    "            ok,msg=tts_generate(text, outstem, state[\"settings\"], default_voice=(sc.get(\"tts\") or {}).get(\"voice\",\"alloy\"))\n",
    "            if not ok:\n",
    "                wav=outstem.with_suffix(\".wav\")\n",
    "                _run([\"ffmpeg\",\"-y\",\"-f\",\"lavfi\",\"-i\",\"anullsrc=r=48000:cl=stereo\",\"-t\",\"2.5\",\"-c:a\",\"pcm_s16le\", str(wav)])\n",
    "                mp3=outstem.with_suffix(\".mp3\")\n",
    "                _run([\"ffmpeg\",\"-y\",\"-i\",str(wav),\"-c:a\",\"libmp3lame\",\"-q:a\",\"4\", str(mp3)])\n",
    "            prov = state[\"settings\"][\"tts\"][\"provider\"]\n",
    "            tgt=None\n",
    "            if prov==\"OPENAI\":\n",
    "                fmt = state[\"settings\"][\"tts\"][\"openai\"].get(\"format\",\"mp3\")\n",
    "                candidate = outstem.with_suffix(f\".{fmt}\")\n",
    "                tgt = candidate if candidate.exists() else (outstem.with_suffix(\".mp3\") if outstem.with_suffix(\".mp3\").exists() else None)\n",
    "            elif prov==\"AZURE\":\n",
    "                tgt = outstem.with_suffix(\".mp3\") if outstem.with_suffix(\".mp3\").exists() else None\n",
    "            else:\n",
    "                fmt = state[\"settings\"][\"tts\"][\"minimax\"].get(\"format\",\"mp3\")\n",
    "                candidate = outstem.with_suffix(f\".{fmt}\")\n",
    "                tgt = candidate if candidate.exists() else (outstem.with_suffix(\".mp3\") if outstem.with_suffix(\".mp3\").exists() else None)\n",
    "            sc[\"audio_file\"] = tgt.name if tgt else sc.get(\"audio_file\")\n",
    "            audio_dd.options=gather_audios(); audio_dd.value=sc.get(\"audio_file\") or \"\"\n",
    "            refresh_audio_player()\n",
    "        tts_btn.on_click(on_tts_click)\n",
    "\n",
    "        def openai_image(prompt: str, out_path: Path, model=\"dall-e-3\", size=\"1792x1024\"):\n",
    "            if not OPENAI_API_KEY: return False,\"缺少 OPENAI_API_KEY\"\n",
    "            import requests, base64\n",
    "            try:\n",
    "                url=\"https://api.openai.com/v1/images/generations\"\n",
    "                headers={\"Authorization\":f\"Bearer {OPENAI_API_KEY}\",\"Content-Type\":\"application/json\"}\n",
    "                if OPENAI_ORG_ID: headers[\"OpenAI-Organization\"]=OPENAI_ORG_ID\n",
    "                payload={\"model\":model,\"prompt\":prompt or \"\",\"size\":size,\"response_format\":\"b64_json\"}\n",
    "                r=requests.post(url,headers=headers,json=payload,timeout=180)\n",
    "                if r.status_code!=200: return False,f\"{r.status_code} {r.text[:160]}\"\n",
    "                b64=(r.json().get(\"data\") or [{}])[0].get(\"b64_json\")\n",
    "                if not b64: return False,\"No b64\"\n",
    "                out_path.write_bytes(base64.b64decode(b64)); return True,\"OK\"\n",
    "            except Exception as e:\n",
    "                return False,f\"Exception {e}\"\n",
    "                \n",
    "        def placeholder_img_local(out_path: Path):\n",
    "            try:\n",
    "                from PIL import Image, ImageDraw\n",
    "                img = Image.new(\"RGB\", (1280, 720), (45, 45, 45))\n",
    "                d = ImageDraw.Draw(img)\n",
    "                d.text((24, 24), \"Placeholder\", fill=(255, 255, 255))\n",
    "                tiny = (\n",
    "                    b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\"\n",
    "                    b\"\\x08\\x02\\x00\\x00\\x00\\x90wS\\xde\\x00\\x00\\x00\\x0cIDAT\\x08\\xd7c\\xf8\\x0f\\x00\\x01\"\n",
    "                    b\"\\x01\\x01\\x00\\x18\\xdd\\x8d\\xe1\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\"\n",
    "                )\n",
    "                try:\n",
    "                    out_path.write_bytes(tiny)\n",
    "                    return True\n",
    "                except Exception:\n",
    "                    return False\n",
    "            except Exception:\n",
    "                return False\n",
    "            \n",
    "\n",
    "        def on_img_click(_b, sc=sc, image_dd=image_dd, preview=preview):\n",
    "            prompt=sc.get(\"ai_prompt\") or sc.get(\"subtitle_text\") or \"\"\n",
    "            outp=main_dir/f\"scene_{sc.get('number'):03d}_img.png\"\n",
    "            ok,msg=openai_image(prompt, outp, model=\"dall-e-3\", size=\"1792x1024\") if OPENAI_API_KEY else (placeholder_img_local(outp), \"OK\")\n",
    "            sc[\"image_file\"]=outp.name if outp.exists() else sc.get(\"image_file\")\n",
    "            image_dd.options=gather_images(); image_dd.value=sc.get(\"image_file\") or \"\"\n",
    "            with preview:\n",
    "                clear_output()\n",
    "                imgf=sc.get(\"image_file\")\n",
    "                if imgf and (main_dir/imgf).exists():\n",
    "                    from IPython.display import Image as IPyImage; display(IPyImage(filename=str(main_dir/imgf)))\n",
    "                else:\n",
    "                    print(\"(尚無圖片)\")\n",
    "        img_btn.on_click(on_img_click)\n",
    "\n",
    "        upper_row=W.HBox([sub_area, W.VBox([W.HBox([audio_dd, tts_btn]), audio_play], layout=W.Layout(width=\"380px\"))], layout=W.Layout(width=\"100%\", align_items=\"flex-start\"))\n",
    "        lower_row=W.HBox([prompt_area, W.HBox([image_dd, img_btn], layout=W.Layout(width=\"380px\"))], layout=W.Layout(width=\"100%\", align_items=\"flex-start\"))\n",
    "        row_panel=W.HBox([W.VBox([upper_row, lower_row], layout=W.Layout(width=\"100%\")), preview], layout=W.Layout(width=\"100%\", align_items=\"flex-start\", justify_content=\"space-between\"))\n",
    "\n",
    "        refresh_audio_player(); rows.append(row_panel)\n",
    "    scenes_box.children=rows\n",
    "\n",
    "def do_import_text(_b=None):\n",
    "    lines=[l.strip() for l in ta_text.value.splitlines() if l.strip()]\n",
    "    if not lines: lines=ensure_text_lines()\n",
    "    if not lines: \n",
    "        with status_out: clear_output(); print(\"沒有文字可建立分鏡。請貼上腳本或建立 text.txt。\"); return\n",
    "    plan=build_plan_from_lines(lines); state[\"plan\"]=plan; rebuild_scenes_ui()\n",
    "    with status_out: clear_output(); print(\"[載入] 已重建分鏡。\")\n",
    "\n",
    "def do_qc(_b=None):\n",
    "    with status_out:\n",
    "        clear_output()\n",
    "        if not state[\"plan\"]: print(\"尚未載入規劃檔。\"); return\n",
    "        print(quickcheck(state[\"plan\"]))\n",
    "\n",
    "def do_refresh_img(_b=None):\n",
    "    rebuild_scenes_ui()\n",
    "    with status_out:\n",
    "        clear_output()\n",
    "        print(\"[重整] 圖片清單已更新。\")\n",
    "\n",
    "def do_refresh_aud(_b=None):\n",
    "    rebuild_scenes_ui()\n",
    "    with status_out:\n",
    "        clear_output()\n",
    "        print(\"[重整] 音訊清單已更新。\")\n",
    "\n",
    "def do_preflight(_b=None):\n",
    "    plan = state[\"plan\"]\n",
    "    with status_out:\n",
    "        clear_output()\n",
    "        if not plan:\n",
    "            print(\"尚未載入規劃。\"); return\n",
    "        meta = {\n",
    "            \"已有 plan_current.yaml\": (main_dir/PLAN_CURRENT).exists(),\n",
    "            \"已有 handshake\": (main_dir/HANDSHAKE_NAME).exists(),\n",
    "            \"已有 lock\": (main_dir/LOCK_NAME).exists(),\n",
    "            \"場景數\": plan_scene_count(plan)\n",
    "        }\n",
    "        print(\"[檢查] \", meta)\n",
    "        # 併入「快速檢查」\n",
    "        print(\"\\n[逐場景檢查]\")\n",
    "        print(quickcheck(plan))\n",
    "\n",
    "def do_save_plan(_b=None):\n",
    "    plan = state[\"plan\"]\n",
    "    if not plan:\n",
    "        with status_out:\n",
    "            clear_output()\n",
    "            print(\"尚未有規劃內容，無法儲存。\")\n",
    "        return\n",
    "\n",
    "    # 只警告，不阻擋儲存（允許分段作業）\n",
    "    missing_audio = [sc.get(\"number\") for sc in plan.get(\"scenes\", [])\n",
    "                     if not sc.get(\"audio_file\") or not (main_dir / sc.get(\"audio_file\")).exists()]\n",
    "\n",
    "    # 向前繼承圖片（第一張之前不補，之後沒指定的用最近一張）\n",
    "    last_img = None\n",
    "    filled = 0\n",
    "    for sc in plan.get(\"scenes\", []):\n",
    "        img = sc.get(\"image_file\")\n",
    "        if img and (main_dir / img).exists():\n",
    "            last_img = img\n",
    "        elif last_img:\n",
    "            sc[\"image_file\"] = last_img\n",
    "            filled += 1\n",
    "\n",
    "    # 寫檔（含備份與握手/鎖）\n",
    "    plan_text = yaml.safe_dump(plan, allow_unicode=True)\n",
    "    bname = backup_plan_yaml(plan_text)\n",
    "    (main_dir / PLAN_CURRENT).write_text(plan_text, encoding=\"utf-8\")\n",
    "    md5 = write_handshake_lock(plan_text, plan_scene_count(plan))\n",
    "\n",
    "    # 立即刷新 UI 讓你看到繼承結果\n",
    "    rebuild_scenes_ui()\n",
    "\n",
    "    # 狀態輸出：成功訊息 + 警告（若有）\n",
    "    with status_out:\n",
    "        clear_output()\n",
    "        print(f\"[儲存] plan_current.yaml 已寫入，場景={plan_scene_count(plan)} md5={md5[:8]}\")\n",
    "        print(f\"[備份] {bname}\")\n",
    "        if filled > 0:\n",
    "            print(f\"已自動補齊缺圖（向前繼承）{filled} 個場景，UI 已刷新。\")\n",
    "        else:\n",
    "            print(\"圖片向前繼承：無需補齊。\")\n",
    "        if missing_audio:\n",
    "            print(f\"⚠️ 警告：以下場景目前缺少音訊（允許先儲存）：{missing_audio}\")\n",
    "            print(\"    提示：可稍後補音再存，或在輸出前用「檔案檢查」確認。\")\n",
    "        else:\n",
    "            print(\"音訊檢查：OK\")\n",
    "            \n",
    "def do_render(_b=None):\n",
    "    plan = state[\"plan\"]\n",
    "    if not plan:\n",
    "        with status_out:\n",
    "            clear_output()\n",
    "            print(\"尚未載入規劃，無法輸出。\")\n",
    "        return\n",
    "\n",
    "    # 核心變更：使用面板即時值，而非讀 settings.json\n",
    "    state[\"settings\"] = collect_settings_from_ui()\n",
    "\n",
    "    # 仍照常落盤 plan / 寫 handshake（不影響設定是否儲存）\n",
    "    plan_text = yaml.safe_dump(plan, allow_unicode=True)\n",
    "    (main_dir/PLAN_CURRENT).write_text(plan_text, encoding=\"utf-8\")\n",
    "    write_handshake_lock(plan_text, plan_scene_count(plan))\n",
    "\n",
    "    with log_out:\n",
    "        clear_output()\n",
    "        print(\"[輸出] 開始處理（使用面板即時設定，未必已儲存到 settings.json）...\")\n",
    "    try:\n",
    "        render_from_plan(plan, log_out, settings=state[\"settings\"])\n",
    "    except Exception as e:\n",
    "        with log_out:\n",
    "            print(\"輸出失敗：\", e)\n",
    "\n",
    "btn_import.on_click(do_import_text); btn_qc.on_click(do_qc); btn_save.on_click(do_save_plan)\n",
    "btn_pre.on_click(do_preflight); btn_render.on_click(do_render)\n",
    "btn_refresh_img.on_click(do_refresh_img); btn_refresh_aud.on_click(do_refresh_aud)\n",
    "\n",
    "controls_row1=W.HBox([btn_import, btn_qc, btn_refresh_img, btn_refresh_aud], layout=W.Layout(flex_flow=\"row wrap\"))\n",
    "controls_row2=W.HBox([btn_save, btn_pre, btn_render], layout=W.Layout(flex_flow=\"row wrap\"))\n",
    "\n",
    "ui=W.VBox([\n",
    "    W.HTML(\"<b>步驟1：分鏡編輯</b> — 每個場景：上框字幕 + 右側音訊選擇/TTS（下一行播放器）；下框圖片提示 + 右側圖片選擇/AI生圖；最右側圖片預覽\"),\n",
    "    ta_text, controls_row1, controls_row2, W.HTML(\"<hr>\"), scenes_box, W.HTML(\"<hr>\"),\n",
    "    W.HTML(\"<b>狀態</b>\"), status_out, W.HTML(\"<b>輸出日誌</b>\"), log_out\n",
    "])\n",
    "display(ui)\n",
    "\n",
    "# 啟動時自動載入既有 plan\n",
    "try:\n",
    "    pc=main_dir/PLAN_CURRENT\n",
    "    if pc.exists():\n",
    "        loaded=yaml.safe_load(pc.read_text(encoding=\"utf-8\"))\n",
    "        if plan_scene_count(loaded)>0:\n",
    "            state[\"plan\"]=loaded; rebuild_scenes_ui()\n",
    "            with status_out: clear_output(); print(f\"[啟動] 已載入 plan_current.yaml 場景={plan_scene_count(loaded)}\"); print(quickcheck(loaded))\n",
    "except Exception as e:\n",
    "    with status_out: clear_output(); print(\"載入既有規劃失敗：\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14fcb57-fe48-4b6d-8db1-53c1e94ebe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## patch函釋，偵錯全黑問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e78fbd6-70e8-462e-88d5-59bd4c89ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def postprocess_final_video(base_plain: Path, settings: dict, out_path: Path, base_w=1920, base_h=1080, base_fps=25, debug=True):\n",
    "    post = (settings.get(\"post\") or {})\n",
    "    nothing = True\n",
    "    if (post.get(\"color\") or {}).get(\"enabled\", False): nothing = False\n",
    "    if (post.get(\"denoise\") or {}).get(\"enabled\", False): nothing = False\n",
    "    if (post.get(\"sharpen\") or {}).get(\"enabled\", False): nothing = False\n",
    "    if (post.get(\"fps_interp\") or {}).get(\"enabled\", False): nothing = False\n",
    "    for ov in (post.get(\"overlays\") or []):\n",
    "        if ov.get(\"enabled\", False): nothing = False\n",
    "\n",
    "    if nothing:\n",
    "        shutil.copyfile(base_plain, out_path)\n",
    "        return True, \"copy\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Build filter chain and get extra_inputs (引入你原來的建構函式)\n",
    "    # ----------------------------------------\n",
    "    extra_inputs, fc, vout = build_filter_chain_and_inputs(base_w, base_h, settings, base_fps=base_fps)\n",
    "\n",
    "    if debug:\n",
    "        print(\"[Debug] base_plain:\", base_plain)\n",
    "        print(\"[Debug] out_path:\", out_path)\n",
    "        print(\"[Debug] extra_inputs:\", extra_inputs)\n",
    "        print(\"[Debug] filter_complex:\", fc)\n",
    "        print(\"[Debug] vout:\", vout)\n",
    "    # --- 找尋 webm overlay ---\n",
    "    webm_overlay = None\n",
    "    for i in range(len(extra_inputs) - 1):\n",
    "        if (\n",
    "            isinstance(extra_inputs[i], str)\n",
    "            and extra_inputs[i] == \"-i\"\n",
    "            and isinstance(extra_inputs[i + 1], str)\n",
    "            and extra_inputs[i + 1].lower().endswith(\".webm\")\n",
    "        ):\n",
    "            webm_overlay = Path(extra_inputs[i + 1])\n",
    "            break\n",
    "    if not webm_overlay:\n",
    "        for item in extra_inputs:\n",
    "            if isinstance(item, str) and item.lower().endswith(\".webm\"):\n",
    "                webm_overlay = Path(item)\n",
    "                break\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 【偵錯版本】若發現 filter_complex 有誤，當場 print 並停下\n",
    "    # ----------------------------------------\n",
    "    if fc is None or not isinstance(fc, str):\n",
    "        print(\"[Error] filter_complex 構建失敗，內容:\", fc)\n",
    "        raise ValueError(\"filter_complex 構建失敗\")\n",
    "    if \"[0:v]\" not in fc:\n",
    "        print(\"[Error] filter_complex 缺少 base input，[0:v] 必須是主序列！\")\n",
    "        raise ValueError(\"filter_complex 疊圖序列缺失（main base）。\")\n",
    "\n",
    "    if webm_overlay and \"overlay\" in fc:\n",
    "        # 這是進階 overlay 的 PNG 疊圖路徑\n",
    "        png_pattern, png_dir = convert_webm_overlay_to_pngs(webm_overlay, \"adv_overlay\", frame_rate=base_fps)\n",
    "        if debug:\n",
    "            print(f\"[Debug] 進階 overlay模式：webm_overlay = {webm_overlay}\")\n",
    "            print(f\"[Debug] png_pattern = {png_pattern}, png_dir = {png_dir}\")\n",
    "        # PNG 疊圖指令\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\", \"-i\", str(base_plain),\n",
    "            \"-framerate\", str(base_fps), \"-i\", png_pattern,\n",
    "            \"-filter_complex\", \"[0:v][1:v]overlay=0:0:shortest=1[v1]\",\n",
    "            \"-map\", \"[v1]\", \"-map\", \"0:a?\",\n",
    "            \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\",\n",
    "            \"-c:a\", \"aac\", \"-movflags\", \"+faststart\", str(out_path)\n",
    "        ]\n",
    "        if debug:\n",
    "            print(\"[Debug] ffmpeg overlay command:\\n \", \" \".join(map(str, cmd)))\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        print(\"----ffmpeg stderr (tail)----\")\n",
    "        print((res.stderr or \"\")[-600:])\n",
    "        print(\"----------------------------\")\n",
    "        cleanup_overlay_pngs(png_dir, \"adv_overlay\")\n",
    "        ok = (res.returncode == 0 and out_path.exists() and out_path.stat().st_size > 0)\n",
    "        if not ok:\n",
    "            print(\"[Error] ffmpeg 疊圖失敗！returncode=\", res.returncode)\n",
    "            print(\"stderr last 800:\\n\", (res.stderr or \"\")[-800:])\n",
    "        return ok, (res.stderr or \"\")[-400:] if not ok else \"ok\"\n",
    "\n",
    "    else:\n",
    "        # 沒有 webm overlay，沿用原底圖與疊圖序列\n",
    "        cmd = [\"ffmpeg\", \"-y\", \"-i\", str(base_plain)] + extra_inputs + [\n",
    "            \"-filter_complex\", fc, \"-map\", f\"[{vout}]\", \"-map\", \"0:a?\",\n",
    "            \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\", \"-c:a\", \"aac\", \"-movflags\", \"+faststart\", str(out_path)\n",
    "        ]\n",
    "        if debug:\n",
    "            print(\"[Debug] ffmpeg non-overlay command:\\n \", \" \".join(map(str, cmd)))\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        print(\"----ffmpeg stderr (tail)----\")\n",
    "        print((res.stderr or \"\")[-600:])\n",
    "        print(\"----------------------------\")\n",
    "        ok = (res.returncode == 0 and out_path.exists() and out_path.stat().st_size > 0)\n",
    "        if not ok:\n",
    "            print(\"[Error] ffmpeg 疊圖失敗！returncode=\", res.returncode)\n",
    "            print(\"stderr last 800:\\n\", (res.stderr or \"\")[-800:])\n",
    "        return ok, (res.stderr or \"\")[-400:] if not ok else \"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03f2c3-e739-4ebe-992b-4ef7ca9357a2",
   "metadata": {},
   "source": [
    "## 底下進行測試為何加特效全黑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d8aa6ea-e8e0-41c9-b314-efd7c7df20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def postprocess_final_video(base_plain: Path, settings: dict, out_path: Path, base_w=1920, base_h=1080, base_fps=25, debug=True):\n",
    "    post = (settings.get(\"post\") or {})\n",
    "    nothing = True\n",
    "    if (post.get(\"color\") or {}).get(\"enabled\", False): nothing = False\n",
    "    if (post.get(\"denoise\") or {}).get(\"enabled\", False): nothing = False\n",
    "    if (post.get(\"sharpen\") or {}).get(\"enabled\", False): nothing = False\n",
    "    if (post.get(\"fps_interp\") or {}).get(\"enabled\", False): nothing = False\n",
    "    for ov in (post.get(\"overlays\") or []):\n",
    "        if ov.get(\"enabled\", False): nothing = False\n",
    "\n",
    "    if nothing:\n",
    "        shutil.copyfile(base_plain, out_path)\n",
    "        return True, \"copy\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Build filter chain and get extra_inputs (引入你原來的建構函式)\n",
    "    # ----------------------------------------\n",
    "    extra_inputs, fc, vout = build_filter_chain_and_inputs(base_w, base_h, settings, base_fps=base_fps)\n",
    "\n",
    "    if debug:\n",
    "        print(\"[Debug] base_plain:\", base_plain)\n",
    "        print(\"[Debug] out_path:\", out_path)\n",
    "        print(\"[Debug] extra_inputs:\", extra_inputs)\n",
    "        print(\"[Debug] filter_complex:\", fc)\n",
    "        print(\"[Debug] vout:\", vout)\n",
    "    # --- 找尋 webm overlay ---\n",
    "    webm_overlay = None\n",
    "    for i in range(len(extra_inputs) - 1):\n",
    "        if (\n",
    "            isinstance(extra_inputs[i], str)\n",
    "            and extra_inputs[i] == \"-i\"\n",
    "            and isinstance(extra_inputs[i + 1], str)\n",
    "            and extra_inputs[i + 1].lower().endswith(\".webm\")\n",
    "        ):\n",
    "            webm_overlay = Path(extra_inputs[i + 1])\n",
    "            break\n",
    "    if not webm_overlay:\n",
    "        for item in extra_inputs:\n",
    "            if isinstance(item, str) and item.lower().endswith(\".webm\"):\n",
    "                webm_overlay = Path(item)\n",
    "                break\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 【偵錯版本】若發現 filter_complex 有誤，當場 print 並停下\n",
    "    # ----------------------------------------\n",
    "    if fc is None or not isinstance(fc, str):\n",
    "        print(\"[Error] filter_complex 構建失敗，內容:\", fc)\n",
    "        raise ValueError(\"filter_complex 構建失敗\")\n",
    "    if \"[0:v]\" not in fc:\n",
    "        print(\"[Error] filter_complex 缺少 base input，[0:v] 必須是主序列！\")\n",
    "        raise ValueError(\"filter_complex 疊圖序列缺失（main base）。\")\n",
    "\n",
    "    if webm_overlay and \"overlay\" in fc:\n",
    "        # 這是進階 overlay 的 PNG 疊圖路徑\n",
    "        png_pattern, png_dir = convert_webm_overlay_to_pngs(webm_overlay, \"adv_overlay\", frame_rate=base_fps)\n",
    "        if debug:\n",
    "            print(f\"[Debug] 進階 overlay模式：webm_overlay = {webm_overlay}\")\n",
    "            print(f\"[Debug] png_pattern = {png_pattern}, png_dir = {png_dir}\")\n",
    "        # PNG 疊圖指令\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\", \"-i\", str(base_plain),\n",
    "            \"-framerate\", str(base_fps), \"-i\", png_pattern,\n",
    "            \"-filter_complex\", \"[0:v][1:v]overlay=0:0:shortest=1[v1]\",\n",
    "            \"-map\", \"[v1]\", \"-map\", \"0:a?\",\n",
    "            \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\",\n",
    "            \"-c:a\", \"aac\", \"-movflags\", \"+faststart\", str(out_path)\n",
    "        ]\n",
    "        if debug:\n",
    "            print(\"[Debug] ffmpeg overlay command:\\n \", \" \".join(map(str, cmd)))\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        print(\"----ffmpeg stderr (tail)----\")\n",
    "        print((res.stderr or \"\")[-600:])\n",
    "        print(\"----------------------------\")\n",
    "        cleanup_overlay_pngs(png_dir, \"adv_overlay\")\n",
    "        ok = (res.returncode == 0 and out_path.exists() and out_path.stat().st_size > 0)\n",
    "        if not ok:\n",
    "            print(\"[Error] ffmpeg 疊圖失敗！returncode=\", res.returncode)\n",
    "            print(\"stderr last 800:\\n\", (res.stderr or \"\")[-800:])\n",
    "        return ok, (res.stderr or \"\")[-400:] if not ok else \"ok\"\n",
    "\n",
    "    else:\n",
    "        # 沒有 webm overlay，沿用原底圖與疊圖序列\n",
    "        cmd = [\"ffmpeg\", \"-y\", \"-i\", str(base_plain)] + extra_inputs + [\n",
    "            \"-filter_complex\", fc, \"-map\", f\"[{vout}]\", \"-map\", \"0:a?\",\n",
    "            \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\", \"-c:a\", \"aac\", \"-movflags\", \"+faststart\", str(out_path)\n",
    "        ]\n",
    "        if debug:\n",
    "            print(\"[Debug] ffmpeg non-overlay command:\\n \", \" \".join(map(str, cmd)))\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        print(\"----ffmpeg stderr (tail)----\")\n",
    "        print((res.stderr or \"\")[-600:])\n",
    "        print(\"----------------------------\")\n",
    "        ok = (res.returncode == 0 and out_path.exists() and out_path.stat().st_size > 0)\n",
    "        if not ok:\n",
    "            print(\"[Error] ffmpeg 疊圖失敗！returncode=\", res.returncode)\n",
    "            print(\"stderr last 800:\\n\", (res.stderr or \"\")[-800:])\n",
    "        return ok, (res.stderr or \"\")[-400:] if not ok else \"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef60b1-e73a-41de-a6ca-dbac1ffa8acd",
   "metadata": {},
   "source": [
    "## 底下為AI逐步測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9373ac8-aefd-4406-a075-e51e0293738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (Rev8, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint --enable-whisper\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'base_plain.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Duration: 00:00:17.00, start: 0.000000, bitrate: 921 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 1920x1080 [SAR 1:1 DAR 16:9], 717 kb/s, 24.87 fps, 25 tbr, 12800 tbn, start 0.010000 (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 96000 Hz, mono, fltp, 196 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #0:1 -> #0:1 (copy)\n",
      "Output #0, mp4, to 'base_test1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 717 kb/s, 24.87 fps, 25 tbr, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 96000 Hz, mono, fltp, 196 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Press [q] to stop, [?] for help\n",
      "[out#0/mp4 @ 000001db3ecdaa00] video:1487KiB audio:408KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.976229%\n",
      "frame=  422 fps=0.0 q=-1.0 Lsize=    1913KiB time=00:00:16.89 bitrate= 927.5kbits/s speed= 836x elapsed=0:00:00.02    \n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -i base_plain.mp4 -c copy base_test1.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d2709a4-8f08-4903-a96d-b86cfb8a02f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (Rev8, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint --enable-whisper\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'base_plain.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Duration: 00:00:17.00, start: 0.000000, bitrate: 921 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 1920x1080 [SAR 1:1 DAR 16:9], 717 kb/s, 24.87 fps, 25 tbr, 12800 tbn, start 0.010000 (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 96000 Hz, mono, fltp, 196 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[in#1 @ 000001925dd918c0] Error opening input: No such file or directory\n",
      "Error opening input file adv_overlay_000001.png.\n",
      "Error opening input files: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -i base_plain.mp4 -i adv_overlay_000001.png -filter_complex \"[0:v][1:v]overlay=0:0\" -frames:v 1 test_overlay_static.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04d85554-eedd-4ff5-8ac3-42a09871597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flyre\\mynotebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbd9c27a-fa6a-4038-a4cd-0a7743175e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_scene_2.png\n",
      "ai_scene_3.png\n",
      "ai_scene_3_gen_0953b.png\n",
      "ai_scene_4.png\n",
      "dalle3_chinese_scene.png\n",
      "dalle3_chinese_scene_1920x1080.png\n",
      "dalle3_chinese_scene_20251031_042326.png\n",
      "dalle3_chinese_scene_20251031_052141.png\n",
      "dalle3_chinese_scene_20251031_052141_1920x1080.png\n",
      "dalle3_chinese_scene_20251101_040029.png\n",
      "dalle3_chinese_scene_20251101_040029_1920x1080.png\n",
      "dalle3_chinese_scene_20251101_042731.png\n",
      "dalle3_chinese_scene_20251101_042731_1920x1080.png\n",
      "dalle3_chinese_scene_20251101_043524.png\n",
      "dalle3_chinese_scene_20251101_043524_1920x1080.png\n",
      "dalle3_chinese_scene_20251101_044234.png\n",
      "dalle3_chinese_scene_20251101_044234_1920x1080.png\n",
      "dalle3_一個人_流星_20251031_042326_1920x1080.png\n",
      "dalle_background.png\n",
      "pillow_test.png\n",
      "rainline_gray_64.png\n",
      "scene_001_img.png\n",
      "Screenshot 2025-10-11 221037.png\n",
      "snowflake_lightblue_64.png\n",
      "test_caption.png\n",
      "_adv_tex_leaves.png\n",
      "_adv_tex_snow.png\n",
      "樹林瀑布.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for f in os.listdir():\n",
    "    if f.endswith(\".png\"):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ef1fac9-a1da-4ff1-9def-2f05886775ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_adv_overlay_L1_1592920c30.webm', '_adv_overlay_L1_dd4dda8988.webm', '_adv_overlay_L2_9abd9334e0.webm']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob(\"*.webm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7450e094-d428-499f-bc67-9db48f818705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (Rev8, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint --enable-whisper\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, matroska,webm, from '_adv_overlay_L1_1592920c30.webm':\n",
      "  Metadata:\n",
      "    ENCODER         : Lavf62.3.100\n",
      "  Duration: 00:00:12.00, start: 0.000000, bitrate: 12935 kb/s\n",
      "  Stream #0:0: Video: vp9 (Profile 0), yuv420p(tv, progressive), 1920x1080, SAR 1:1 DAR 16:9, 25 fps, 25 tbr, 1k tbn\n",
      "    Metadata:\n",
      "      alpha_mode      : 1\n",
      "      ENCODER         : Lavc62.11.100 libvpx-vp9\n",
      "      DURATION        : 00:00:12.000000000\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (vp9 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to '_overlaytemp/adv_overlay_%06d.png':\n",
      "  Metadata:\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0: Video: png, rgb24(pc, gbr/unknown/unknown, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.11.100 png\n",
      "      alpha_mode      : 1\n",
      "      DURATION        : 00:00:12.000000000\n",
      "frame=   14 fps=0.0 q=-0.0 size=N/A time=00:00:00.56 bitrate=N/A speed=1.07x elapsed=0:00:00.52    \n",
      "frame=   34 fps= 33 q=-0.0 size=N/A time=00:00:01.36 bitrate=N/A speed=1.31x elapsed=0:00:01.03    \n",
      "frame=   55 fps= 34 q=-0.0 size=N/A time=00:00:02.20 bitrate=N/A speed=1.37x elapsed=0:00:01.60    \n",
      "frame=   68 fps= 32 q=-0.0 size=N/A time=00:00:02.72 bitrate=N/A speed=1.27x elapsed=0:00:02.14    \n",
      "frame=   91 fps= 33 q=-0.0 size=N/A time=00:00:03.64 bitrate=N/A speed=1.34x elapsed=0:00:02.72    \n",
      "frame=  109 fps= 33 q=-0.0 size=N/A time=00:00:04.36 bitrate=N/A speed=1.32x elapsed=0:00:03.29    \n",
      "frame=  125 fps= 33 q=-0.0 size=N/A time=00:00:05.00 bitrate=N/A speed=1.31x elapsed=0:00:03.82    \n",
      "frame=  148 fps= 34 q=-0.0 size=N/A time=00:00:05.92 bitrate=N/A speed=1.35x elapsed=0:00:04.37    \n",
      "frame=  171 fps= 35 q=-0.0 size=N/A time=00:00:06.84 bitrate=N/A speed=1.39x elapsed=0:00:04.92    \n",
      "frame=  188 fps= 34 q=-0.0 size=N/A time=00:00:07.52 bitrate=N/A speed=1.37x elapsed=0:00:05.49    \n",
      "frame=  209 fps= 35 q=-0.0 size=N/A time=00:00:08.36 bitrate=N/A speed=1.39x elapsed=0:00:06.03    \n",
      "frame=  232 fps= 35 q=-0.0 size=N/A time=00:00:09.28 bitrate=N/A speed= 1.4x elapsed=0:00:06.60    \n",
      "frame=  250 fps= 35 q=-0.0 size=N/A time=00:00:10.00 bitrate=N/A speed= 1.4x elapsed=0:00:07.13    \n",
      "frame=  268 fps= 35 q=-0.0 size=N/A time=00:00:10.72 bitrate=N/A speed= 1.4x elapsed=0:00:07.67    \n",
      "frame=  291 fps= 36 q=-0.0 size=N/A time=00:00:11.64 bitrate=N/A speed=1.42x elapsed=0:00:08.19    \n",
      "[out#0/image2 @ 0000027c6cb0a280] video:47355KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=  300 fps= 36 q=-0.0 Lsize=N/A time=00:00:12.00 bitrate=N/A speed=1.44x elapsed=0:00:08.35    \n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -i _adv_overlay_L1_1592920c30.webm -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\" _overlaytemp/adv_overlay_%06d.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c211b46-eab9-420b-be88-5db65ad24329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (Rev8, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint --enable-whisper\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'base_plain.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Duration: 00:00:17.00, start: 0.000000, bitrate: 921 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 1920x1080 [SAR 1:1 DAR 16:9], 717 kb/s, 24.87 fps, 25 tbr, 12800 tbn, start 0.010000 (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 96000 Hz, mono, fltp, 196 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Input #1, png_pipe, from '_overlaytemp/adv_overlay_000001.png':\n",
      "  Duration: N/A, bitrate: N/A\n",
      "  Stream #1:0: Video: png, rgb24(pc, gbr/unknown/unknown), 1920x1080 [SAR 1:1 DAR 16:9], 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> overlay\n",
      "  Stream #1:0 (png) -> overlay\n",
      "  overlay:default -> Stream #0:0 (png)\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0000021c7c45e180] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to 'test_overlay_static.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0: Video: png, rgb24(pc, gbr/unknown/unknown, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.11.100 png\n",
      "[image2 @ 0000021c7664e5c0] The specified filename 'test_overlay_static.png' does not contain an image sequence pattern or a pattern is invalid.\n",
      "[image2 @ 0000021c7664e5c0] Use a pattern such as %03d for an image sequence or use the -update option (with -frames:v 1 if needed) to write a single image.\n",
      "[out#0/image2 @ 0000021c7664e4c0] video:94KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=    1 fps=0.0 q=-0.0 Lsize=N/A time=00:00:00.04 bitrate=N/A speed=0.252x elapsed=0:00:00.15    \n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -i base_plain.mp4 -i _overlaytemp/adv_overlay_000001.png -filter_complex \"[0:v][1:v]overlay=0:0\" -frames:v 1 test_overlay_static.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2e3db99-b504-465a-812c-986a39b5134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: RGB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"_overlaytemp/adv_overlay_000001.png\")  # 依你的png實際路徑\n",
    "print(\"mode:\", img.mode)\n",
    "img.show()\n",
    "if \"A\" in img.mode:\n",
    "    img_alpha = img.getchannel(\"A\")\n",
    "    img_alpha.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c3bc4ff-5b4d-4a49-8f8d-4a5f133061b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, matroska,webm, from '_adv_overlay_L1_1592920c30.webm':\n",
      "  Metadata:\n",
      "    ENCODER         : Lavf62.3.100\n",
      "  Duration: 00:00:12.00, start: 0.000000, bitrate: 12935 kb/s\n",
      "  Stream #0:0: Video: vp9 (Profile 0), yuv420p(tv, progressive), 1920x1080, SAR 1:1 DAR 16:9, 25 fps, 25 tbr, 1k tbn\n",
      "    Metadata:\n",
      "      alpha_mode      : 1\n",
      "      ENCODER         : Lavc62.11.100 libvpx-vp9\n",
      "      DURATION        : 00:00:12.000000000\n",
      "At least one output file must be specified\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -hide_banner -i _adv_overlay_L1_1592920c30.webm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e087ec0f-7134-4ab6-94f1-fc95e0ae4f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGBA\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('花瓣透明圖.png')\n",
    "print(img.mode)  # RGBA 代表有透明通道，RGB 沒有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab5c5f5-8b85-44e6-9c72-b2cb7817c668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (Rev8, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint --enable-whisper\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'base_plain.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Duration: 00:00:17.00, start: 0.000000, bitrate: 921 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 1920x1080 [SAR 1:1 DAR 16:9], 717 kb/s, 24.87 fps, 25 tbr, 12800 tbn, start 0.010000 (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 96000 Hz, mono, fltp, 196 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 00000275e4b55e40] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to 'frames/base_%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0(und): Video: png, rgb24(pc, gbr/unknown/unknown, progressive), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.11.100 png\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "frame=   10 fps=0.0 q=-0.0 size=N/A time=00:00:00.40 bitrate=N/A speed=0.722x elapsed=0:00:00.55    \n",
      "frame=   29 fps= 27 q=-0.0 size=N/A time=00:00:01.16 bitrate=N/A speed=1.07x elapsed=0:00:01.07    \n",
      "frame=   50 fps= 31 q=-0.0 size=N/A time=00:00:02.00 bitrate=N/A speed=1.26x elapsed=0:00:01.59    \n",
      "frame=   75 fps= 35 q=-0.0 size=N/A time=00:00:03.00 bitrate=N/A speed=1.41x elapsed=0:00:02.13    \n",
      "frame=   90 fps= 34 q=-0.0 size=N/A time=00:00:03.60 bitrate=N/A speed=1.34x elapsed=0:00:02.68    \n",
      "frame=  112 fps= 35 q=-0.0 size=N/A time=00:00:04.48 bitrate=N/A dup=1 drop=0 speed=1.39x elapsed=0:00:03.21    \n",
      "frame=  134 fps= 36 q=-0.0 size=N/A time=00:00:05.36 bitrate=N/A dup=1 drop=0 speed=1.42x elapsed=0:00:03.77    \n",
      "frame=  157 fps= 36 q=-0.0 size=N/A time=00:00:06.28 bitrate=N/A dup=1 drop=0 speed=1.45x elapsed=0:00:04.32    \n",
      "frame=  180 fps= 37 q=-0.0 size=N/A time=00:00:07.20 bitrate=N/A dup=1 drop=0 speed=1.48x elapsed=0:00:04.86    \n",
      "frame=  200 fps= 37 q=-0.0 size=N/A time=00:00:08.00 bitrate=N/A dup=2 drop=0 speed=1.49x elapsed=0:00:05.38    \n",
      "frame=  226 fps= 38 q=-0.0 size=N/A time=00:00:09.04 bitrate=N/A dup=2 drop=0 speed=1.51x elapsed=0:00:05.99    \n",
      "frame=  243 fps= 37 q=-0.0 size=N/A time=00:00:09.72 bitrate=N/A dup=2 drop=0 speed=1.48x elapsed=0:00:06.56    \n",
      "frame=  256 fps= 36 q=-0.0 size=N/A time=00:00:10.24 bitrate=N/A dup=2 drop=0 speed=1.44x elapsed=0:00:07.10    \n",
      "frame=  271 fps= 35 q=-0.0 size=N/A time=00:00:10.84 bitrate=N/A dup=2 drop=0 speed=1.41x elapsed=0:00:07.68    \n",
      "frame=  287 fps= 35 q=-0.0 size=N/A time=00:00:11.48 bitrate=N/A dup=2 drop=0 speed=1.39x elapsed=0:00:08.23    \n",
      "frame=  298 fps= 34 q=-0.0 size=N/A time=00:00:11.92 bitrate=N/A dup=2 drop=0 speed=1.36x elapsed=0:00:08.74    \n",
      "frame=  322 fps= 35 q=-0.0 size=N/A time=00:00:12.88 bitrate=N/A dup=2 drop=0 speed=1.38x elapsed=0:00:09.31    \n",
      "frame=  345 fps= 35 q=-0.0 size=N/A time=00:00:13.80 bitrate=N/A dup=2 drop=0 speed= 1.4x elapsed=0:00:09.85    \n",
      "frame=  369 fps= 35 q=-0.0 size=N/A time=00:00:14.76 bitrate=N/A dup=2 drop=0 speed=1.42x elapsed=0:00:10.41    \n",
      "frame=  392 fps= 36 q=-0.0 size=N/A time=00:00:15.68 bitrate=N/A dup=2 drop=0 speed=1.43x elapsed=0:00:10.96    \n",
      "frame=  420 fps= 37 q=-0.0 size=N/A time=00:00:16.80 bitrate=N/A dup=2 drop=0 speed=1.46x elapsed=0:00:11.50    \n",
      "[out#0/image2 @ 00000275e0d8ad40] video:150416KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=  424 fps= 37 q=-0.0 Lsize=N/A time=00:00:16.96 bitrate=N/A dup=2 drop=0 speed=1.47x elapsed=0:00:11.55    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "main_dir = r\"C:/Users/flyre/mynotebooks\"\n",
    "os.chdir(main_dir)\n",
    "os.makedirs(\"frames\", exist_ok=True)\n",
    "\n",
    "# 拆幀，寬640，高度自動等比例\n",
    "!ffmpeg -y -i base_plain.mp4 -vf \"scale=640:-1\" frames/base_%04d.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750d81e4-55e2-4eb0-b804-2783c8c1cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petal.png mode: RGBA\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "petal = Image.open('花瓣透明圖.png')\n",
    "print('petal.png mode:', petal.mode)\n",
    "petal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01fa062-681c-4ca1-879d-a52d8eb81925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "左上alpha: 0\n",
      "中間alpha: 255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "petal = Image.open('花瓣透明圖.png').convert('RGBA')\n",
    "arr = np.array(petal)\n",
    "print('左上alpha:', arr[0,0,3])  # [0,0,3] 是左上pixel的alpha\n",
    "print('中間alpha:', arr[arr.shape[0]//2, arr.shape[1]//2, 3])  # 圖中央"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c80621a-8353-4b5f-85e2-4d7841131003",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(petal)\n",
    "# 只要alpha==0就該是背景，設成假紅色檢查\n",
    "arr[(arr[:,:,3]==0)] = [255,0,0,255]\n",
    "Image.fromarray(arr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea6b6081-dc50-48db-ba6b-036993521a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "os.makedirs(\"out1\", exist_ok=True)\n",
    "frame_files = sorted(glob.glob('frames/base_*.png'))\n",
    "\n",
    "for fn in frame_files:\n",
    "    frame = Image.open(fn).convert('RGBA')\n",
    "    frame_out = frame.copy()\n",
    "    petal = Image.open('花瓣透明圖.png').convert('RGBA')\n",
    "    frame_out.paste(petal, (60, 120), petal)\n",
    "    outname = 'out1/' + os.path.basename(fn)\n",
    "    frame_out.save(outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecd3049-70c4-497d-8f79-d59f134003de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "os.makedirs(\"out2\", exist_ok=True)\n",
    "frame_files = sorted(glob.glob('out1/base_*.png'))\n",
    "\n",
    "for fn in frame_files:\n",
    "    img = Image.open(fn).convert('RGBA')\n",
    "    petal2 = Image.open('花瓣透明圖.png').convert('RGBA')\n",
    "    petal2.putalpha(int(255*0.2))  # 透明度設 0.2\n",
    "    img.paste(petal2, (230, 250), petal2)  # 疊上淡花瓣（不同位置）\n",
    "    outname = 'out2/' + os.path.basename(fn)\n",
    "    img.save(outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924bbe65-8817-414d-aa77-cfb712c04bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (Rev8, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint --enable-whisper\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, image2, from 'out2/base_%04d.png':\n",
      "  Duration: 00:00:14.13, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc, gbr/unknown/unknown), 640x360, 30 fps, 30 tbr, 30 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 000002aa726bb4c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 000002aa726bb4c0] profile High, level 3.0, 4:2:0, 8-bit\n",
      "[libx264 @ 000002aa726bb4c0] 264 - core 165 r3222 b35605a - H.264/MPEG-4 AVC codec - Copyleft 2003-2025 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'demo_out.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 640x360, q=2-31, 30 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=    0 fps=0.0 q=0.0 size=       0KiB time=N/A bitrate=N/A speed=N/A elapsed=0:00:00.53    \n",
      "frame=   60 fps= 57 q=29.0 size=       0KiB time=00:00:01.93 bitrate=   0.2kbits/s speed=1.83x elapsed=0:00:01.05    \n",
      "frame=   94 fps= 60 q=29.0 size=       0KiB time=00:00:03.06 bitrate=   0.1kbits/s speed=1.96x elapsed=0:00:01.56    \n",
      "frame=  128 fps= 61 q=29.0 size=       0KiB time=00:00:04.20 bitrate=   0.1kbits/s speed=2.01x elapsed=0:00:02.08    \n",
      "frame=  163 fps= 62 q=29.0 size=       0KiB time=00:00:05.36 bitrate=   0.1kbits/s speed=2.05x elapsed=0:00:02.61    \n",
      "frame=  197 fps= 63 q=29.0 size=       0KiB time=00:00:06.50 bitrate=   0.1kbits/s speed=2.08x elapsed=0:00:03.13    \n",
      "frame=  232 fps= 64 q=29.0 size=       0KiB time=00:00:07.66 bitrate=   0.1kbits/s speed= 2.1x elapsed=0:00:03.65    \n",
      "frame=  267 fps= 64 q=29.0 size=       0KiB time=00:00:08.83 bitrate=   0.0kbits/s speed=2.11x elapsed=0:00:04.18    \n",
      "frame=  301 fps= 64 q=29.0 size=       0KiB time=00:00:09.96 bitrate=   0.0kbits/s speed=2.11x elapsed=0:00:04.71    \n",
      "frame=  336 fps= 64 q=29.0 size=       0KiB time=00:00:11.13 bitrate=   0.0kbits/s speed=2.13x elapsed=0:00:05.23    \n",
      "frame=  388 fps= 67 q=29.0 size=       0KiB time=00:00:12.86 bitrate=   0.0kbits/s speed=2.22x elapsed=0:00:05.79    \n",
      "[out#0/mp4 @ 000002aa71c59580] video:147KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 3.950517%\n",
      "frame=  424 fps= 72 q=-1.0 Lsize=     153KiB time=00:00:14.06 bitrate=  88.9kbits/s speed=2.39x elapsed=0:00:05.87    \n",
      "[libx264 @ 000002aa726bb4c0] frame I:2     Avg QP:17.89  size: 68987\n",
      "[libx264 @ 000002aa726bb4c0] frame P:107   Avg QP:19.58  size:    57\n",
      "[libx264 @ 000002aa726bb4c0] frame B:315   Avg QP:30.34  size:    18\n",
      "[libx264 @ 000002aa726bb4c0] consecutive B-frames:  0.9%  0.0%  0.0% 99.1%\n",
      "[libx264 @ 000002aa726bb4c0] mb I  I16..4:  0.5% 48.8% 50.7%\n",
      "[libx264 @ 000002aa726bb4c0] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.5%  0.0%  0.0%  0.0%  0.0%    skip:98.5%\n",
      "[libx264 @ 000002aa726bb4c0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.1%  0.0%  0.0%  direct: 0.0%  skip:99.9%  L0: 2.2% L1:97.8% BI: 0.0%\n",
      "[libx264 @ 000002aa726bb4c0] 8x8 transform intra:48.8% inter:75.0%\n",
      "[libx264 @ 000002aa726bb4c0] coded y,uvDC,uvAC intra: 97.4% 99.4% 92.9% inter: 0.0% 0.4% 0.0%\n",
      "[libx264 @ 000002aa726bb4c0] i16 v,h,dc,p:  0% 10% 10% 80%\n",
      "[libx264 @ 000002aa726bb4c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  9% 20% 11%  6% 12%  8% 14%  7% 12%\n",
      "[libx264 @ 000002aa726bb4c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 15%  9%  7% 14% 10% 13%  7% 10%\n",
      "[libx264 @ 000002aa726bb4c0] i8c dc,h,v,p: 45% 28% 11% 15%\n",
      "[libx264 @ 000002aa726bb4c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 000002aa726bb4c0] ref P L0: 92.7%  0.5%  5.6%  1.2%\n",
      "[libx264 @ 000002aa726bb4c0] ref B L1: 91.6%  8.4%\n",
      "[libx264 @ 000002aa726bb4c0] kb/s:84.76\n",
      "ffmpeg version 8.0-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (Rev8, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint --enable-whisper\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, image2, from 'out2/base_%04d.png':\n",
      "  Duration: 00:00:14.13, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc, gbr/unknown/unknown), 640x360, 30 fps, 30 tbr, 30 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> vp9 (libvpx-vp9))\n",
      "Press [q] to stop, [?] for help\n",
      "[libvpx-vp9 @ 0000016f12a8b580] v1.15.2-100-g40561f514\n",
      "[libvpx-vp9 @ 0000016f12a8b580] Neither bitrate nor constrained quality specified, using default CRF of 32\n",
      "Output #0, webm, to 'demo_out.webm':\n",
      "  Metadata:\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0: Video: vp9, yuva420p(tv, progressive), 640x360, q=2-31, 30 fps, 1k tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.11.100 libvpx-vp9\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=    0 fps=0.0 q=0.0 size=       0KiB time=N/A bitrate=N/A speed=N/A elapsed=0:00:00.52    \n",
      "frame=   14 fps= 13 q=32.0 size=       0KiB time=00:00:00.46 bitrate=   8.2kbits/s speed=0.447x elapsed=0:00:01.04    \n",
      "frame=   26 fps= 17 q=32.0 size=       0KiB time=00:00:00.86 bitrate=   4.4kbits/s speed=0.559x elapsed=0:00:01.54    \n",
      "frame=   38 fps= 18 q=32.0 size=       0KiB time=00:00:01.26 bitrate=   3.0kbits/s speed=0.613x elapsed=0:00:02.06    \n",
      "frame=   49 fps= 19 q=21.0 size=       0KiB time=00:00:01.63 bitrate=   2.3kbits/s speed=0.633x elapsed=0:00:02.58    \n",
      "frame=   60 fps= 19 q=32.0 size=       0KiB time=00:00:02.00 bitrate=   1.9kbits/s speed=0.646x elapsed=0:00:03.09    \n",
      "frame=   70 fps= 19 q=32.0 size=       0KiB time=00:00:02.33 bitrate=   1.6kbits/s speed=0.643x elapsed=0:00:03.62    \n",
      "frame=   81 fps= 20 q=21.0 size=       0KiB time=00:00:02.70 bitrate=   1.4kbits/s speed=0.652x elapsed=0:00:04.14    \n",
      "frame=   92 fps= 20 q=32.0 size=       0KiB time=00:00:03.06 bitrate=   1.2kbits/s speed=0.656x elapsed=0:00:04.67    \n",
      "frame=   99 fps= 19 q=30.0 size=       0KiB time=00:00:03.30 bitrate=   1.2kbits/s speed=0.632x elapsed=0:00:05.22    \n",
      "frame=  106 fps= 18 q=32.0 size=       0KiB time=00:00:03.53 bitrate=   1.1kbits/s speed=0.615x elapsed=0:00:05.74    \n",
      "frame=  116 fps= 19 q=32.0 size=       0KiB time=00:00:03.86 bitrate=   1.0kbits/s speed=0.618x elapsed=0:00:06.25    \n",
      "frame=  127 fps= 19 q=30.0 size=       0KiB time=00:00:04.23 bitrate=   0.9kbits/s speed=0.626x elapsed=0:00:06.76    \n",
      "frame=  131 fps= 18 q=30.0 size=      72KiB time=00:00:04.36 bitrate= 134.5kbits/s speed=0.599x elapsed=0:00:07.29    \n",
      "frame=  145 fps= 19 q=21.0 size=      72KiB time=00:00:04.83 bitrate= 121.5kbits/s speed=0.619x elapsed=0:00:07.80    \n",
      "frame=  156 fps= 19 q=32.0 size=      72KiB time=00:00:05.20 bitrate= 112.9kbits/s speed=0.625x elapsed=0:00:08.32    \n",
      "frame=  166 fps= 19 q=32.0 size=      72KiB time=00:00:05.53 bitrate= 106.1kbits/s speed=0.626x elapsed=0:00:08.84    \n",
      "frame=  177 fps= 19 q=21.0 size=      72KiB time=00:00:05.90 bitrate=  99.5kbits/s speed=0.631x elapsed=0:00:09.34    \n",
      "frame=  189 fps= 19 q=21.0 size=      72KiB time=00:00:06.30 bitrate=  93.2kbits/s speed=0.638x elapsed=0:00:09.87    \n",
      "frame=  201 fps= 19 q=21.0 size=      72KiB time=00:00:06.70 bitrate=  87.6kbits/s speed=0.645x elapsed=0:00:10.38    \n",
      "frame=  214 fps= 20 q=32.0 size=      72KiB time=00:00:07.13 bitrate=  82.3kbits/s speed=0.655x elapsed=0:00:10.89    \n",
      "frame=  226 fps= 20 q=32.0 size=      72KiB time=00:00:07.53 bitrate=  78.0kbits/s speed=0.66x elapsed=0:00:11.40    \n",
      "frame=  238 fps= 20 q=32.0 size=      72KiB time=00:00:07.93 bitrate=  74.0kbits/s speed=0.665x elapsed=0:00:11.92    \n",
      "frame=  251 fps= 20 q=30.0 size=      72KiB time=00:00:08.36 bitrate=  70.2kbits/s speed=0.673x elapsed=0:00:12.44    \n",
      "frame=  257 fps= 20 q=10.0 size=      72KiB time=00:00:08.56 bitrate=  68.6kbits/s speed=0.661x elapsed=0:00:12.96    \n",
      "frame=  272 fps= 20 q=32.0 size=     143KiB time=00:00:09.06 bitrate= 129.1kbits/s speed=0.672x elapsed=0:00:13.48    \n",
      "frame=  284 fps= 20 q=32.0 size=     143KiB time=00:00:09.46 bitrate= 123.7kbits/s speed=0.676x elapsed=0:00:14.00    \n",
      "frame=  296 fps= 20 q=32.0 size=     143KiB time=00:00:09.86 bitrate= 118.7kbits/s speed=0.68x elapsed=0:00:14.51    \n",
      "frame=  308 fps= 20 q=32.0 size=     143KiB time=00:00:10.26 bitrate= 114.0kbits/s speed=0.683x elapsed=0:00:15.03    \n",
      "frame=  320 fps= 21 q=32.0 size=     143KiB time=00:00:10.66 bitrate= 109.8kbits/s speed=0.686x elapsed=0:00:15.55    \n",
      "frame=  332 fps= 21 q=32.0 size=     143KiB time=00:00:11.06 bitrate= 105.8kbits/s speed=0.689x elapsed=0:00:16.06    \n",
      "frame=  343 fps= 21 q=30.0 size=     143KiB time=00:00:11.43 bitrate= 102.4kbits/s speed=0.689x elapsed=0:00:16.60    \n",
      "frame=  351 fps= 21 q=30.0 size=     143KiB time=00:00:11.70 bitrate= 100.1kbits/s speed=0.684x elapsed=0:00:17.11    \n",
      "frame=  359 fps= 20 q=30.0 size=     143KiB time=00:00:11.96 bitrate=  97.8kbits/s speed=0.679x elapsed=0:00:17.62    \n",
      "frame=  368 fps= 20 q=32.0 size=     143KiB time=00:00:12.26 bitrate=  95.4kbits/s speed=0.676x elapsed=0:00:18.14    \n",
      "frame=  380 fps= 20 q=32.0 size=     143KiB time=00:00:12.66 bitrate=  92.4kbits/s speed=0.679x elapsed=0:00:18.66    \n",
      "frame=  387 fps= 20 q=30.0 size=     214KiB time=00:00:12.90 bitrate= 136.0kbits/s speed=0.672x elapsed=0:00:19.18    \n",
      "frame=  400 fps= 20 q=32.0 size=     214KiB time=00:00:13.33 bitrate= 131.5kbits/s speed=0.677x elapsed=0:00:19.68    \n",
      "frame=  400 fps= 20 q=32.0 size=     214KiB time=00:00:13.33 bitrate= 131.5kbits/s speed=0.66x elapsed=0:00:20.20    \n",
      "[out#0/webm @ 0000016f11f79f00] video:252KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 10.449707%\n",
      "frame=  424 fps= 21 q=32.0 Lsize=     279KiB time=00:00:14.13 bitrate= 161.6kbits/s speed=0.689x elapsed=0:00:20.50    \n"
     ]
    }
   ],
   "source": [
    "# 產生 MP4（不帶透明度，只供一般觀看）\n",
    "!ffmpeg -y -framerate 30 -i out2/base_%04d.png -c:v libx264 -pix_fmt yuv420p demo_out.mp4\n",
    "\n",
    "# 產生 WebM（帶透明度的格式，僅 VP8/VP9 + yuva420p 可做到）\n",
    "!ffmpeg -y -framerate 30 -i out2/base_%04d.png -c:v libvpx-vp9 -pix_fmt yuva420p demo_out.webm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda9a5d-71de-4195-a58b-76a3e2e8b3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}